{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "Wk7-assignment-class7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codesamskaaraH/WU_assignments/blob/main/Wk7_assignment_class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgNjEIDh2vX9"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSJl8ZoSucQK"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
        "\n",
        "**Module 7 Assignment: Computer Vision Neural Network**\n",
        "\n",
        "**Student Name: Your Name**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okt7vSL52vYC"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7xrVUBv2vYE",
        "outputId": "4c919cb4-37e6-4a47-f118-9811dfa95f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return f\"{h}:{m:>02}:{s:>05.2f}\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eCUTf6n3BCb"
      },
      "source": [
        "# Assignment Submit Function\n",
        "\n",
        "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n",
        "\n",
        "**It is unlikely that should need to modify this function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHb2ceEO3Qil"
      },
      "source": [
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import io\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - List of pandas dataframes or images.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    payload = []\n",
        "    for item in data:\n",
        "        if type(item) is PIL.Image.Image:\n",
        "            buffered = BytesIO()\n",
        "            item.save(buffered, format=\"PNG\")\n",
        "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
        "        elif type(item) is pd.core.frame.DataFrame:\n",
        "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
        "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code==200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vNkxmQDucQN"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "For this assignment, you will use YOLO running on Google CoLab.  I suggest that you run this assignment on CoLab because the example code below is already setup to get you started with the correct versions of  YOLO on TensorFlow 2.0.\n",
        "\n",
        "For this assignment you are provided with 10 image files that contain 10 different webcam pictures taken at the [Venice Sidewalk Cafe](https://www.westland.net/beachcam/) a WebCam that has been in opration since 1996.  You can find the 10 images here:\n",
        "\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.png\n",
        "\n",
        "You can see a sample of the WebCam here:\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png)\n",
        "\n",
        "YOLO does quite well-recognizing objects in this webcam, as the following image illustrates.\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/predictions.jpg)\n",
        "\n",
        "You are to write a script that counts the number of certain objects in each of the images.  Specifically, you are looking for:\n",
        "\n",
        "* person\n",
        "* car\n",
        "* bicycle\n",
        "* motorbike\n",
        "* umbrella\n",
        "* handbag\n",
        "\n",
        "It is essential that your use YOLO with a threshold of 10% if you want your results to match mine. The sample code below already contains this setting.  Your program can set this threshold with the following command.\n",
        "\n",
        "* FLAGS.yolo_score_threshold = 0.1\n",
        "\n",
        "Your submitted data frame should also contain a column that identifies which image generated each row.  This column should be named **image** and contain integer numbers between 1 and 10.  There should be 10 rows in total.  The complete data frame should look something like this (not necessarily exactly these numbers).\n",
        "\n",
        "|image|person|car|bicycle|motorbike|umbrella|handbag|\n",
        "|-|-|-|-|-|-|-|\n",
        "|1|23|0|3|4|0|0|\n",
        "|2|27|1|8|2|0|0|\n",
        "|3|29|0|0|0|3|0|\n",
        "|...|...|...|...|...|...|...|\n",
        "\n",
        "\n",
        "The following code sets up YOLO and then dumps the classification information for the first image.  This notebook only serves to get you started.  Read in all ten images and generate a data frame that looks like the following. Use the **submit** function as you did in previous assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI9XFHWf2vYY"
      },
      "source": [
        "### Installing YoloV3-TF2\n",
        "\n",
        "The following code is taken from the module, it installs YoLoV3-TF2 if not already installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCM70ViM2vYZ",
        "outputId": "0956bc46-ea74-45b1-baa0-68ed740730bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install git+https://github.com/zzh8829/yolov3-tf2.git@master"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/zzh8829/yolov3-tf2.git@master\n",
            "  Cloning https://github.com/zzh8829/yolov3-tf2.git (to revision master) to /tmp/pip-req-build-kz87x2uc\n",
            "  Running command git clone -q https://github.com/zzh8829/yolov3-tf2.git /tmp/pip-req-build-kz87x2uc\n",
            "Requirement already satisfied (use --upgrade to upgrade): yolov3-tf2==0.1 from git+https://github.com/zzh8829/yolov3-tf2.git@master in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: yolov3-tf2\n",
            "  Building wheel for yolov3-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yolov3-tf2: filename=yolov3_tf2-0.1-cp36-none-any.whl size=8851 sha256=53894e89f336d9b2bdc29412e7899613206d866966fb0ea883d1af5f0111ebbf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hxl1_wy_/wheels/59/1b/97/905ab51e9c0330efe8c3c518aff17de4ee91100412cd6dd553\n",
            "Successfully built yolov3-tf2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyWQeEDu2vYf"
      },
      "source": [
        "The following code is taken from the module, it downloads needed files for YoLoV3-TF2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2ZVTgPO2vYf",
        "outputId": "e7fd83f5-757a-4ef3-93f3-2bfa320cc287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "if COLAB:\n",
        "  ROOT = '/content/drive/My Drive/projects/t81_558_dlearning/yolo'\n",
        "else:\n",
        "  ROOT = os.path.join(os.getcwd(),'data')\n",
        "\n",
        "filename_darknet_weights = tf.keras.utils.get_file(\n",
        "    os.path.join(ROOT,'yolov3.weights'),\n",
        "    origin='https://pjreddie.com/media/files/yolov3.weights')\n",
        "TINY = False\n",
        "\n",
        "filename_convert_script = tf.keras.utils.get_file(\n",
        "    os.path.join(os.getcwd(),'convert.py'),\n",
        "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py')\n",
        "\n",
        "filename_classes = tf.keras.utils.get_file(\n",
        "    os.path.join(ROOT,'coco.names'),\n",
        "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/data/coco.names')\n",
        "filename_converted_weights = os.path.join(ROOT,'yolov3.tf')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://pjreddie.com/media/files/yolov3.weights\n",
            "248012800/248007048 [==============================] - 984s 4us/step\n",
            "Downloading data from https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py\n",
            "8192/1277 [================================================================================================================================================================================================] - 0s 0us/step\n",
            "Downloading data from https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/data/coco.names\n",
            "8192/625 [=========================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99-qKwt-2vYl"
      },
      "source": [
        "### Transfering Weights\n",
        "\n",
        "The following code is taken from the module, it transfers preloaded weights into YOLO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woAO2zJP2vYl",
        "outputId": "0d9b4912-4200-4adc-ce12-2bb3d5d37845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys\n",
        "!{sys.executable} \"{filename_convert_script}\" --weights \"{filename_darknet_weights}\" --output \"{filename_converted_weights}\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-24 19:03:09.927949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-24 19:03:11.801861: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-24 19:03:11.851271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-24 19:03:11.851877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-10-24 19:03:11.851919: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-24 19:03:12.039237: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-24 19:03:12.196169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-24 19:03:12.209824: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-24 19:03:12.491249: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-24 19:03:12.504385: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-24 19:03:13.024486: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-24 19:03:13.024687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-24 19:03:13.025358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-24 19:03:13.025888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-24 19:03:13.100008: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-10-24 19:03:13.100206: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1eb6a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-24 19:03:13.100234: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-24 19:03:13.238202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-24 19:03:13.238904: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1eb6f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-24 19:03:13.238939: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-24 19:03:13.239630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-24 19:03:13.240194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-10-24 19:03:13.240240: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-24 19:03:13.240293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-24 19:03:13.240319: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-24 19:03:13.240346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-24 19:03:13.240371: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-24 19:03:13.240395: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-24 19:03:13.240418: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-24 19:03:13.240494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-24 19:03:13.241076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-24 19:03:13.241566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-24 19:03:13.244118: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-24 19:03:17.031201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-24 19:03:17.031260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-24 19:03:17.031272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-24 19:03:17.034967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-24 19:03:17.035626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-24 19:03:17.036271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Model: \"yolov3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "yolo_darknet (Functional)       ((None, None, None,  40620640    input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_0 (Functional)        (None, None, None, 5 11024384    yolo_darknet[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_1 (Functional)        (None, None, None, 2 2957312     yolo_conv_0[0][0]                \n",
            "                                                                 yolo_darknet[0][1]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_2 (Functional)        (None, None, None, 1 741376      yolo_conv_1[0][0]                \n",
            "                                                                 yolo_darknet[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_0 (Functional)      (None, None, None, 3 4984063     yolo_conv_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_1 (Functional)      (None, None, None, 3 1312511     yolo_conv_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_2 (Functional)      (None, None, None, 3 361471      yolo_conv_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_0 (Lambda)           ((None, None, None,  0           yolo_output_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_1 (Lambda)           ((None, None, None,  0           yolo_output_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_2 (Lambda)           ((None, None, None,  0           yolo_output_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_nms (Lambda)               ((None, 100, 4), (No 0           yolo_boxes_0[0][0]               \n",
            "                                                                 yolo_boxes_0[0][1]               \n",
            "                                                                 yolo_boxes_0[0][2]               \n",
            "                                                                 yolo_boxes_1[0][0]               \n",
            "                                                                 yolo_boxes_1[0][1]               \n",
            "                                                                 yolo_boxes_1[0][2]               \n",
            "                                                                 yolo_boxes_2[0][0]               \n",
            "                                                                 yolo_boxes_2[0][1]               \n",
            "                                                                 yolo_boxes_2[0][2]               \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "I1024 19:03:19.975803 140488084965248 convert.py:24] model created\n",
            "I1024 19:03:19.992213 140488084965248 utils.py:45] yolo_darknet/conv2d bn\n",
            "I1024 19:03:19.995260 140488084965248 utils.py:45] yolo_darknet/conv2d_1 bn\n",
            "I1024 19:03:19.998692 140488084965248 utils.py:45] yolo_darknet/conv2d_2 bn\n",
            "I1024 19:03:20.001312 140488084965248 utils.py:45] yolo_darknet/conv2d_3 bn\n",
            "I1024 19:03:20.004326 140488084965248 utils.py:45] yolo_darknet/conv2d_4 bn\n",
            "I1024 19:03:20.008072 140488084965248 utils.py:45] yolo_darknet/conv2d_5 bn\n",
            "I1024 19:03:20.010970 140488084965248 utils.py:45] yolo_darknet/conv2d_6 bn\n",
            "I1024 19:03:20.014292 140488084965248 utils.py:45] yolo_darknet/conv2d_7 bn\n",
            "I1024 19:03:20.017054 140488084965248 utils.py:45] yolo_darknet/conv2d_8 bn\n",
            "I1024 19:03:20.020488 140488084965248 utils.py:45] yolo_darknet/conv2d_9 bn\n",
            "I1024 19:03:20.026720 140488084965248 utils.py:45] yolo_darknet/conv2d_10 bn\n",
            "I1024 19:03:20.029721 140488084965248 utils.py:45] yolo_darknet/conv2d_11 bn\n",
            "I1024 19:03:20.034721 140488084965248 utils.py:45] yolo_darknet/conv2d_12 bn\n",
            "I1024 19:03:20.037953 140488084965248 utils.py:45] yolo_darknet/conv2d_13 bn\n",
            "I1024 19:03:20.042856 140488084965248 utils.py:45] yolo_darknet/conv2d_14 bn\n",
            "I1024 19:03:20.045695 140488084965248 utils.py:45] yolo_darknet/conv2d_15 bn\n",
            "I1024 19:03:20.050255 140488084965248 utils.py:45] yolo_darknet/conv2d_16 bn\n",
            "I1024 19:03:20.052995 140488084965248 utils.py:45] yolo_darknet/conv2d_17 bn\n",
            "I1024 19:03:20.057626 140488084965248 utils.py:45] yolo_darknet/conv2d_18 bn\n",
            "I1024 19:03:20.060446 140488084965248 utils.py:45] yolo_darknet/conv2d_19 bn\n",
            "I1024 19:03:20.065067 140488084965248 utils.py:45] yolo_darknet/conv2d_20 bn\n",
            "I1024 19:03:20.067804 140488084965248 utils.py:45] yolo_darknet/conv2d_21 bn\n",
            "I1024 19:03:20.072607 140488084965248 utils.py:45] yolo_darknet/conv2d_22 bn\n",
            "I1024 19:03:20.075466 140488084965248 utils.py:45] yolo_darknet/conv2d_23 bn\n",
            "I1024 19:03:20.080327 140488084965248 utils.py:45] yolo_darknet/conv2d_24 bn\n",
            "I1024 19:03:20.083113 140488084965248 utils.py:45] yolo_darknet/conv2d_25 bn\n",
            "I1024 19:03:20.087806 140488084965248 utils.py:45] yolo_darknet/conv2d_26 bn\n",
            "I1024 19:03:20.101772 140488084965248 utils.py:45] yolo_darknet/conv2d_27 bn\n",
            "I1024 19:03:20.105558 140488084965248 utils.py:45] yolo_darknet/conv2d_28 bn\n",
            "I1024 19:03:20.116787 140488084965248 utils.py:45] yolo_darknet/conv2d_29 bn\n",
            "I1024 19:03:20.120358 140488084965248 utils.py:45] yolo_darknet/conv2d_30 bn\n",
            "I1024 19:03:20.131424 140488084965248 utils.py:45] yolo_darknet/conv2d_31 bn\n",
            "I1024 19:03:20.134958 140488084965248 utils.py:45] yolo_darknet/conv2d_32 bn\n",
            "I1024 19:03:20.146422 140488084965248 utils.py:45] yolo_darknet/conv2d_33 bn\n",
            "I1024 19:03:20.150077 140488084965248 utils.py:45] yolo_darknet/conv2d_34 bn\n",
            "I1024 19:03:20.161413 140488084965248 utils.py:45] yolo_darknet/conv2d_35 bn\n",
            "I1024 19:03:20.164907 140488084965248 utils.py:45] yolo_darknet/conv2d_36 bn\n",
            "I1024 19:03:20.178667 140488084965248 utils.py:45] yolo_darknet/conv2d_37 bn\n",
            "I1024 19:03:20.182920 140488084965248 utils.py:45] yolo_darknet/conv2d_38 bn\n",
            "I1024 19:03:20.196257 140488084965248 utils.py:45] yolo_darknet/conv2d_39 bn\n",
            "I1024 19:03:20.200111 140488084965248 utils.py:45] yolo_darknet/conv2d_40 bn\n",
            "I1024 19:03:20.211652 140488084965248 utils.py:45] yolo_darknet/conv2d_41 bn\n",
            "I1024 19:03:20.215616 140488084965248 utils.py:45] yolo_darknet/conv2d_42 bn\n",
            "I1024 19:03:20.227319 140488084965248 utils.py:45] yolo_darknet/conv2d_43 bn\n",
            "I1024 19:03:20.280181 140488084965248 utils.py:45] yolo_darknet/conv2d_44 bn\n",
            "I1024 19:03:20.289062 140488084965248 utils.py:45] yolo_darknet/conv2d_45 bn\n",
            "I1024 19:03:20.336128 140488084965248 utils.py:45] yolo_darknet/conv2d_46 bn\n",
            "I1024 19:03:20.344519 140488084965248 utils.py:45] yolo_darknet/conv2d_47 bn\n",
            "I1024 19:03:20.396392 140488084965248 utils.py:45] yolo_darknet/conv2d_48 bn\n",
            "I1024 19:03:20.404842 140488084965248 utils.py:45] yolo_darknet/conv2d_49 bn\n",
            "I1024 19:03:20.451714 140488084965248 utils.py:45] yolo_darknet/conv2d_50 bn\n",
            "I1024 19:03:20.460110 140488084965248 utils.py:45] yolo_darknet/conv2d_51 bn\n",
            "I1024 19:03:20.507496 140488084965248 utils.py:45] yolo_conv_0/conv2d_52 bn\n",
            "I1024 19:03:20.515520 140488084965248 utils.py:45] yolo_conv_0/conv2d_53 bn\n",
            "I1024 19:03:20.561581 140488084965248 utils.py:45] yolo_conv_0/conv2d_54 bn\n",
            "I1024 19:03:20.569425 140488084965248 utils.py:45] yolo_conv_0/conv2d_55 bn\n",
            "I1024 19:03:20.615597 140488084965248 utils.py:45] yolo_conv_0/conv2d_56 bn\n",
            "I1024 19:03:20.623872 140488084965248 utils.py:45] yolo_output_0/conv2d_57 bn\n",
            "I1024 19:03:20.670207 140488084965248 utils.py:45] yolo_output_0/conv2d_58 bias\n",
            "I1024 19:03:20.674366 140488084965248 utils.py:45] yolo_conv_1/conv2d_59 bn\n",
            "I1024 19:03:20.681164 140488084965248 utils.py:45] yolo_conv_1/conv2d_60 bn\n",
            "I1024 19:03:20.684909 140488084965248 utils.py:45] yolo_conv_1/conv2d_61 bn\n",
            "I1024 19:03:20.698560 140488084965248 utils.py:45] yolo_conv_1/conv2d_62 bn\n",
            "I1024 19:03:20.702059 140488084965248 utils.py:45] yolo_conv_1/conv2d_63 bn\n",
            "I1024 19:03:20.713709 140488084965248 utils.py:45] yolo_conv_1/conv2d_64 bn\n",
            "I1024 19:03:20.717183 140488084965248 utils.py:45] yolo_output_1/conv2d_65 bn\n",
            "I1024 19:03:20.728415 140488084965248 utils.py:45] yolo_output_1/conv2d_66 bias\n",
            "I1024 19:03:20.730806 140488084965248 utils.py:45] yolo_conv_2/conv2d_67 bn\n",
            "I1024 19:03:20.733410 140488084965248 utils.py:45] yolo_conv_2/conv2d_68 bn\n",
            "I1024 19:03:20.736253 140488084965248 utils.py:45] yolo_conv_2/conv2d_69 bn\n",
            "I1024 19:03:20.740863 140488084965248 utils.py:45] yolo_conv_2/conv2d_70 bn\n",
            "I1024 19:03:20.743493 140488084965248 utils.py:45] yolo_conv_2/conv2d_71 bn\n",
            "I1024 19:03:20.747985 140488084965248 utils.py:45] yolo_conv_2/conv2d_72 bn\n",
            "I1024 19:03:20.750587 140488084965248 utils.py:45] yolo_output_2/conv2d_73 bn\n",
            "I1024 19:03:20.756293 140488084965248 utils.py:45] yolo_output_2/conv2d_74 bias\n",
            "I1024 19:03:20.758322 140488084965248 convert.py:27] weights loaded\n",
            "2020-10-24 19:03:20.781591: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-24 19:03:25.798978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "I1024 19:03:27.773009 140488084965248 convert.py:31] sanity check passed\n",
            "I1024 19:03:29.417799 140488084965248 convert.py:34] weights saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj_qRv3N2vYp"
      },
      "source": [
        "Now that we have all of the files needed for YOLO, we are ready to use it to recognize components of an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PSGz0NN2vYq"
      },
      "source": [
        "import os\n",
        "os.remove(filename_convert_script)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2x1e_GX2vYt"
      },
      "source": [
        "# Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjTVwPfq2vYu"
      },
      "source": [
        "import time\n",
        "from absl import app, flags, logging\n",
        "from absl.flags import FLAGS\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (YoloV3, YoloV3Tiny)\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "import sys\n",
        "from PIL import Image, ImageFile\n",
        "import requests\n",
        "\n",
        "# Flags are used to define several options for YOLO.\n",
        "flags.DEFINE_string('classes', filename_classes, 'path to classes file')\n",
        "flags.DEFINE_string('weights', filename_converted_weights, 'path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
        "FLAGS([sys.argv[0]])\n",
        "\n",
        "# Locate devices to run YOLO on (e.g. GPU)\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RIXzsbs2vYw",
        "outputId": "dba9ee26-9ff4-4b05-85d1-42b8535fc95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# This assignment does not use the \"Tiny version\"\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "\n",
        "# Load weights and classes\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "print('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "print('classes loaded')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights loaded\n",
            "classes loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE3zz5HH2vY0"
      },
      "source": [
        "Modify the code below to create your solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxjM7Uac2vY0",
        "outputId": "6aad1c63-2e9c-45c9-cab0-12b572246a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "i = 1\n",
        "url = f\"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{i}.png\"\n",
        "response = requests.get(url)\n",
        "img_raw = tf.image.decode_image(response.content, channels=3)\n",
        "\n",
        "# Preprocess image\n",
        "img = tf.expand_dims(img_raw, 0)\n",
        "img = transform_images(img, FLAGS.size)\n",
        "\n",
        "# Desired threshold (any sub-image below this confidence level will be ignored.)\n",
        "FLAGS.yolo_score_threshold = 0.1\n",
        "\n",
        "# Recognize and report results\n",
        "boxes, scores, classes, nums = yolo(img)\n",
        "\n",
        "col_list = ['image','person','car','bicycle','motorbike','umbrella','handbag']\n",
        "submit_df = pd.DataFrame(columns= col_list)\n",
        "\n",
        "submit_df.loc[submit_df['id'].isin(ids), 'other_column'] += 1\n",
        "\n",
        "#for i in range(nums[0]):\n",
        " #   class_names[int(classes[0][i]) == 'person'\n",
        "\n",
        "\n",
        "\n",
        "print('detections:')\n",
        "for i in range(nums[0]):\n",
        "    cls = class_names[int(classes[0][i])]\n",
        "    score = np.array(scores[0][i])\n",
        "    box = np.array(boxes[0][i])\n",
        "    print(f\"\\t{cls}, {score}, {box}\")\n",
        "\n",
        "# This is your student key that I emailed to you at the beginnning of the semester.\n",
        "key = \"JNAl4M33jgax0oM1GJFuF6QHnAk58HWT3FElTJwQ\"  # This is an example key and will not work.\n",
        "\n",
        "# You must also identify your source file.  (modify for your local setup)\n",
        "# file='/content/drive/My Drive/Colab Notebooks/assignment_yourname_class7.ipynb'  # Google CoLab\n",
        "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class7.ipynb'  # Windows\n",
        "file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class7.ipynb'  # Mac/Linux\n",
        "\n",
        "#submit(source_file=file,data=[submit_df],key=key,no=7)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(31, shape=(), dtype=int32)\n",
            "detections:\n",
            "\tperson, 0.8610939383506775, [0.6191845  0.59739566 0.6455239  0.6964505 ]\n",
            "\tperson, 0.8247124552726746, [0.5645817 0.6453511 0.595969  0.7455805]\n",
            "\tperson, 0.79351407289505, [0.6079407  0.69781303 0.6366278  0.7886913 ]\n",
            "\tperson, 0.7164221405982971, [0.6633641 0.6810441 0.6887379 0.7944299]\n",
            "\tperson, 0.6968550682067871, [0.09189358 0.33121657 0.111054   0.37928265]\n",
            "\tperson, 0.6268397569656372, [0.11293058 0.32814595 0.1336746  0.38183174]\n",
            "\tperson, 0.5897690057754517, [0.6063562  0.754396   0.63623744 0.84774655]\n",
            "\tperson, 0.43654847145080566, [0.8495312 0.4620815 0.8663175 0.5087753]\n",
            "\tperson, 0.4356961250305176, [0.43019527 0.74990773 0.47327548 0.8516606 ]\n",
            "\tperson, 0.4281291961669922, [0.59075445 0.6240619  0.61355954 0.6932853 ]\n",
            "\tperson, 0.39086875319480896, [0.808963  0.5757502 0.8373168 0.6760718]\n",
            "\tperson, 0.37690871953964233, [0.5117131  0.60740215 0.5481817  0.71740025]\n",
            "\tperson, 0.37344589829444885, [0.42949548 0.7256865  0.46626833 0.79150695]\n",
            "\tperson, 0.3069878816604614, [0.3984463  0.5203366  0.4362013  0.61008453]\n",
            "\tperson, 0.3038461208343506, [0.5358126  0.6031282  0.56915295 0.7174909 ]\n",
            "\tperson, 0.2955860495567322, [0.65262705 0.7223847  0.67923063 0.8030238 ]\n",
            "\tperson, 0.2951661944389343, [0.7784145  0.7773565  0.80293584 0.90131044]\n",
            "\tmotorbike, 0.2879984378814697, [0.50301605 0.65149045 0.54730684 0.72112453]\n",
            "\tperson, 0.226292684674263, [0.55625015 0.63573825 0.58670956 0.7355976 ]\n",
            "\tmotorbike, 0.2003164440393448, [0.4301363  0.7773609  0.47228858 0.85768104]\n",
            "\tmotorbike, 0.1963585764169693, [0.39544085 0.78764945 0.43075624 0.85294145]\n",
            "\tperson, 0.19133204221725464, [0.76667327 0.47130704 0.78793555 0.5575557 ]\n",
            "\tbicycle, 0.1506638079881668, [0.4301363  0.7773609  0.47228858 0.85768104]\n",
            "\tperson, 0.13832353055477142, [0.8051935  0.4202181  0.83031243 0.4867506 ]\n",
            "\tperson, 0.1335996836423874, [0.75360006 0.4718305  0.7774052  0.55769   ]\n",
            "\tbicycle, 0.13281355798244476, [0.39544085 0.78764945 0.43075624 0.85294145]\n",
            "\tbicycle, 0.13062629103660583, [0.49793977 0.6538797  0.561223   0.72036964]\n",
            "\tperson, 0.11089739203453064, [0.5361232  0.59820485 0.5715708  0.66090786]\n",
            "\tperson, 0.10892567783594131, [0.43477708 0.723783   0.45917106 0.767683  ]\n",
            "\tbench, 0.10668456554412842, [0.446218   0.3652647  0.49337965 0.39149672]\n",
            "\tmotorbike, 0.10645316541194916, [0.7992575  0.61630136 0.8361037  0.67813164]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYEW3R5OCpP5",
        "outputId": "b745aa3b-3b32-4ebc-b74f-e9c401594c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "submit_df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>person</th>\n",
              "      <th>car</th>\n",
              "      <th>bicycle</th>\n",
              "      <th>motorbike</th>\n",
              "      <th>umbrella</th>\n",
              "      <th>handbag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [image, person, car, bicycle, motorbike, umbrella, handbag]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGKf3JMLDs1S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}