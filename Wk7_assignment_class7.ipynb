{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "Wk7-assignment-class7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codesamskaaraH/WU_assignments/blob/main/Wk7_assignment_class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgNjEIDh2vX9"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSJl8ZoSucQK"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
        "\n",
        "**Module 7 Assignment: Computer Vision Neural Network**\n",
        "\n",
        "**Student Name: Shashi Rao**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okt7vSL52vYC"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7xrVUBv2vYE",
        "outputId": "eb7fc1e0-f773-4f41-9266-19b82dc00627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return f\"{h}:{m:>02}:{s:>05.2f}\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eCUTf6n3BCb"
      },
      "source": [
        "# Assignment Submit Function\n",
        "\n",
        "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n",
        "\n",
        "**It is unlikely that should need to modify this function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHb2ceEO3Qil"
      },
      "source": [
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import io\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - List of pandas dataframes or images.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    payload = []\n",
        "    for item in data:\n",
        "        if type(item) is PIL.Image.Image:\n",
        "            buffered = BytesIO()\n",
        "            item.save(buffered, format=\"PNG\")\n",
        "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
        "        elif type(item) is pd.core.frame.DataFrame:\n",
        "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
        "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code==200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vNkxmQDucQN"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "For this assignment, you will use YOLO running on Google CoLab.  I suggest that you run this assignment on CoLab because the example code below is already setup to get you started with the correct versions of  YOLO on TensorFlow 2.0.\n",
        "\n",
        "For this assignment you are provided with 10 image files that contain 10 different webcam pictures taken at the [Venice Sidewalk Cafe](https://www.westland.net/beachcam/) a WebCam that has been in opration since 1996.  You can find the 10 images here:\n",
        "\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.png\n",
        "\n",
        "You can see a sample of the WebCam here:\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png)\n",
        "\n",
        "YOLO does quite well-recognizing objects in this webcam, as the following image illustrates.\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/predictions.jpg)\n",
        "\n",
        "You are to write a script that counts the number of certain objects in each of the images.  Specifically, you are looking for:\n",
        "\n",
        "* person\n",
        "* car\n",
        "* bicycle\n",
        "* motorbike\n",
        "* umbrella\n",
        "* handbag\n",
        "\n",
        "It is essential that your use YOLO with a threshold of 10% if you want your results to match mine. The sample code below already contains this setting.  Your program can set this threshold with the following command.\n",
        "\n",
        "* FLAGS.yolo_score_threshold = 0.1\n",
        "\n",
        "Your submitted data frame should also contain a column that identifies which image generated each row.  This column should be named **image** and contain integer numbers between 1 and 10.  There should be 10 rows in total.  The complete data frame should look something like this (not necessarily exactly these numbers).\n",
        "\n",
        "|image|person|car|bicycle|motorbike|umbrella|handbag|\n",
        "|-|-|-|-|-|-|-|\n",
        "|1|23|0|3|4|0|0|\n",
        "|2|27|1|8|2|0|0|\n",
        "|3|29|0|0|0|3|0|\n",
        "|...|...|...|...|...|...|...|\n",
        "\n",
        "\n",
        "The following code sets up YOLO and then dumps the classification information for the first image.  This notebook only serves to get you started.  Read in all ten images and generate a data frame that looks like the following. Use the **submit** function as you did in previous assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI9XFHWf2vYY"
      },
      "source": [
        "### Installing YoloV3-TF2\n",
        "\n",
        "The following code is taken from the module, it installs YoLoV3-TF2 if not already installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCM70ViM2vYZ",
        "outputId": "a97c49e3-68ae-4708-be0a-63973457c238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install git+https://github.com/zzh8829/yolov3-tf2.git@master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/zzh8829/yolov3-tf2.git@master\n",
            "  Cloning https://github.com/zzh8829/yolov3-tf2.git (to revision master) to /tmp/pip-req-build-whnh52pc\n",
            "  Running command git clone -q https://github.com/zzh8829/yolov3-tf2.git /tmp/pip-req-build-whnh52pc\n",
            "Building wheels for collected packages: yolov3-tf2\n",
            "  Building wheel for yolov3-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yolov3-tf2: filename=yolov3_tf2-0.1-cp36-none-any.whl size=8851 sha256=c7ec6acd780a083d31fa5f08a1e66b52547d092883fe1f8bee91e31b6db00d36\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-79_izgs3/wheels/59/1b/97/905ab51e9c0330efe8c3c518aff17de4ee91100412cd6dd553\n",
            "Successfully built yolov3-tf2\n",
            "Installing collected packages: yolov3-tf2\n",
            "Successfully installed yolov3-tf2-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyWQeEDu2vYf"
      },
      "source": [
        "The following code is taken from the module, it downloads needed files for YoLoV3-TF2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2ZVTgPO2vYf",
        "outputId": "b6290b03-ecba-4369-b257-6bdc01b7e07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "if COLAB:\n",
        "  ROOT = '/content/drive/My Drive/projects/t81_558_dlearning/yolo'\n",
        "else:\n",
        "  ROOT = os.path.join(os.getcwd(),'data')\n",
        "\n",
        "filename_darknet_weights = tf.keras.utils.get_file(\n",
        "    os.path.join(ROOT,'yolov3.weights'),\n",
        "    origin='https://pjreddie.com/media/files/yolov3.weights')\n",
        "TINY = False\n",
        "\n",
        "filename_convert_script = tf.keras.utils.get_file(\n",
        "    os.path.join(os.getcwd(),'convert.py'),\n",
        "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py')\n",
        "\n",
        "filename_classes = tf.keras.utils.get_file(\n",
        "    os.path.join(ROOT,'coco.names'),\n",
        "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/data/coco.names')\n",
        "filename_converted_weights = os.path.join(ROOT,'yolov3.tf')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py\n",
            "8192/1277 [================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99-qKwt-2vYl"
      },
      "source": [
        "### Transfering Weights\n",
        "\n",
        "The following code is taken from the module, it transfers preloaded weights into YOLO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woAO2zJP2vYl",
        "outputId": "3d1583dc-e975-4e7c-9ac1-d9cc77cd215a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys\n",
        "!{sys.executable} \"{filename_convert_script}\" --weights \"{filename_darknet_weights}\" --output \"{filename_converted_weights}\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-26 00:43:39.391243: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-26 00:43:41.306774: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-26 00:43:41.358896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-26 00:43:41.359540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-10-26 00:43:41.359584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-26 00:43:41.549351: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-26 00:43:41.700834: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-26 00:43:41.723218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-26 00:43:41.996263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-26 00:43:42.012340: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-26 00:43:42.534943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-26 00:43:42.535126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-26 00:43:42.535853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-26 00:43:42.536396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-26 00:43:42.605682: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-10-26 00:43:42.605897: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x26e6a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-26 00:43:42.605928: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-26 00:43:42.742096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-26 00:43:42.742841: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x26e6f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-26 00:43:42.742870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-26 00:43:42.743925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-26 00:43:42.744479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-10-26 00:43:42.744538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-26 00:43:42.744599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-26 00:43:42.744620: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-26 00:43:42.744643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-26 00:43:42.744662: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-26 00:43:42.744680: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-26 00:43:42.744699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-26 00:43:42.744764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-26 00:43:42.745326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-26 00:43:42.745873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-26 00:43:42.748361: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-26 00:43:46.511585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-26 00:43:46.511652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-26 00:43:46.511665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-26 00:43:46.515551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-26 00:43:46.516163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-26 00:43:46.516770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Model: \"yolov3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "yolo_darknet (Functional)       ((None, None, None,  40620640    input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_0 (Functional)        (None, None, None, 5 11024384    yolo_darknet[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_1 (Functional)        (None, None, None, 2 2957312     yolo_conv_0[0][0]                \n",
            "                                                                 yolo_darknet[0][1]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_2 (Functional)        (None, None, None, 1 741376      yolo_conv_1[0][0]                \n",
            "                                                                 yolo_darknet[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_0 (Functional)      (None, None, None, 3 4984063     yolo_conv_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_1 (Functional)      (None, None, None, 3 1312511     yolo_conv_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_2 (Functional)      (None, None, None, 3 361471      yolo_conv_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_0 (Lambda)           ((None, None, None,  0           yolo_output_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_1 (Lambda)           ((None, None, None,  0           yolo_output_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_2 (Lambda)           ((None, None, None,  0           yolo_output_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_nms (Lambda)               ((None, 100, 4), (No 0           yolo_boxes_0[0][0]               \n",
            "                                                                 yolo_boxes_0[0][1]               \n",
            "                                                                 yolo_boxes_0[0][2]               \n",
            "                                                                 yolo_boxes_1[0][0]               \n",
            "                                                                 yolo_boxes_1[0][1]               \n",
            "                                                                 yolo_boxes_1[0][2]               \n",
            "                                                                 yolo_boxes_2[0][0]               \n",
            "                                                                 yolo_boxes_2[0][1]               \n",
            "                                                                 yolo_boxes_2[0][2]               \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "I1026 00:43:49.581746 140005746440064 convert.py:24] model created\n",
            "I1026 00:43:49.925872 140005746440064 utils.py:45] yolo_darknet/conv2d bn\n",
            "I1026 00:43:49.932435 140005746440064 utils.py:45] yolo_darknet/conv2d_1 bn\n",
            "I1026 00:43:49.938035 140005746440064 utils.py:45] yolo_darknet/conv2d_2 bn\n",
            "I1026 00:43:49.941973 140005746440064 utils.py:45] yolo_darknet/conv2d_3 bn\n",
            "I1026 00:43:49.944230 140005746440064 utils.py:45] yolo_darknet/conv2d_4 bn\n",
            "I1026 00:43:49.947089 140005746440064 utils.py:45] yolo_darknet/conv2d_5 bn\n",
            "I1026 00:43:49.949159 140005746440064 utils.py:45] yolo_darknet/conv2d_6 bn\n",
            "I1026 00:43:49.951811 140005746440064 utils.py:45] yolo_darknet/conv2d_7 bn\n",
            "I1026 00:43:49.953841 140005746440064 utils.py:45] yolo_darknet/conv2d_8 bn\n",
            "I1026 00:43:49.956255 140005746440064 utils.py:45] yolo_darknet/conv2d_9 bn\n",
            "I1026 00:43:49.961647 140005746440064 utils.py:45] yolo_darknet/conv2d_10 bn\n",
            "I1026 00:43:49.964107 140005746440064 utils.py:45] yolo_darknet/conv2d_11 bn\n",
            "I1026 00:43:49.968324 140005746440064 utils.py:45] yolo_darknet/conv2d_12 bn\n",
            "I1026 00:43:49.970981 140005746440064 utils.py:45] yolo_darknet/conv2d_13 bn\n",
            "I1026 00:43:50.064701 140005746440064 utils.py:45] yolo_darknet/conv2d_14 bn\n",
            "I1026 00:43:50.067378 140005746440064 utils.py:45] yolo_darknet/conv2d_15 bn\n",
            "I1026 00:43:50.071747 140005746440064 utils.py:45] yolo_darknet/conv2d_16 bn\n",
            "I1026 00:43:50.074208 140005746440064 utils.py:45] yolo_darknet/conv2d_17 bn\n",
            "I1026 00:43:50.078613 140005746440064 utils.py:45] yolo_darknet/conv2d_18 bn\n",
            "I1026 00:43:50.081094 140005746440064 utils.py:45] yolo_darknet/conv2d_19 bn\n",
            "I1026 00:43:50.309497 140005746440064 utils.py:45] yolo_darknet/conv2d_20 bn\n",
            "I1026 00:43:50.316091 140005746440064 utils.py:45] yolo_darknet/conv2d_21 bn\n",
            "I1026 00:43:50.335850 140005746440064 utils.py:45] yolo_darknet/conv2d_22 bn\n",
            "I1026 00:43:50.344344 140005746440064 utils.py:45] yolo_darknet/conv2d_23 bn\n",
            "I1026 00:43:50.414715 140005746440064 utils.py:45] yolo_darknet/conv2d_24 bn\n",
            "I1026 00:43:50.420771 140005746440064 utils.py:45] yolo_darknet/conv2d_25 bn\n",
            "I1026 00:43:50.449391 140005746440064 utils.py:45] yolo_darknet/conv2d_26 bn\n",
            "I1026 00:43:50.461579 140005746440064 utils.py:45] yolo_darknet/conv2d_27 bn\n",
            "I1026 00:43:50.464574 140005746440064 utils.py:45] yolo_darknet/conv2d_28 bn\n",
            "I1026 00:43:50.474191 140005746440064 utils.py:45] yolo_darknet/conv2d_29 bn\n",
            "I1026 00:43:50.476963 140005746440064 utils.py:45] yolo_darknet/conv2d_30 bn\n",
            "I1026 00:43:50.486788 140005746440064 utils.py:45] yolo_darknet/conv2d_31 bn\n",
            "I1026 00:43:50.489815 140005746440064 utils.py:45] yolo_darknet/conv2d_32 bn\n",
            "I1026 00:43:50.499860 140005746440064 utils.py:45] yolo_darknet/conv2d_33 bn\n",
            "I1026 00:43:50.502767 140005746440064 utils.py:45] yolo_darknet/conv2d_34 bn\n",
            "I1026 00:43:50.512666 140005746440064 utils.py:45] yolo_darknet/conv2d_35 bn\n",
            "I1026 00:43:50.515568 140005746440064 utils.py:45] yolo_darknet/conv2d_36 bn\n",
            "I1026 00:43:50.554976 140005746440064 utils.py:45] yolo_darknet/conv2d_37 bn\n",
            "I1026 00:43:50.558053 140005746440064 utils.py:45] yolo_darknet/conv2d_38 bn\n",
            "I1026 00:43:50.567944 140005746440064 utils.py:45] yolo_darknet/conv2d_39 bn\n",
            "I1026 00:43:50.570863 140005746440064 utils.py:45] yolo_darknet/conv2d_40 bn\n",
            "I1026 00:43:50.580799 140005746440064 utils.py:45] yolo_darknet/conv2d_41 bn\n",
            "I1026 00:43:50.583853 140005746440064 utils.py:45] yolo_darknet/conv2d_42 bn\n",
            "I1026 00:43:50.605870 140005746440064 utils.py:45] yolo_darknet/conv2d_43 bn\n",
            "I1026 00:43:50.713847 140005746440064 utils.py:45] yolo_darknet/conv2d_44 bn\n",
            "I1026 00:43:50.721589 140005746440064 utils.py:45] yolo_darknet/conv2d_45 bn\n",
            "I1026 00:43:51.222375 140005746440064 utils.py:45] yolo_darknet/conv2d_46 bn\n",
            "I1026 00:43:51.238320 140005746440064 utils.py:45] yolo_darknet/conv2d_47 bn\n",
            "I1026 00:43:51.448183 140005746440064 utils.py:45] yolo_darknet/conv2d_48 bn\n",
            "I1026 00:43:51.503814 140005746440064 utils.py:45] yolo_darknet/conv2d_49 bn\n",
            "I1026 00:43:51.688132 140005746440064 utils.py:45] yolo_darknet/conv2d_50 bn\n",
            "I1026 00:43:51.702191 140005746440064 utils.py:45] yolo_darknet/conv2d_51 bn\n",
            "I1026 00:43:51.963719 140005746440064 utils.py:45] yolo_conv_0/conv2d_52 bn\n",
            "I1026 00:43:51.972123 140005746440064 utils.py:45] yolo_conv_0/conv2d_53 bn\n",
            "I1026 00:43:52.022111 140005746440064 utils.py:45] yolo_conv_0/conv2d_54 bn\n",
            "I1026 00:43:52.029823 140005746440064 utils.py:45] yolo_conv_0/conv2d_55 bn\n",
            "I1026 00:43:52.079072 140005746440064 utils.py:45] yolo_conv_0/conv2d_56 bn\n",
            "I1026 00:43:52.086958 140005746440064 utils.py:45] yolo_output_0/conv2d_57 bn\n",
            "I1026 00:43:52.133695 140005746440064 utils.py:45] yolo_output_0/conv2d_58 bias\n",
            "I1026 00:43:52.137463 140005746440064 utils.py:45] yolo_conv_1/conv2d_59 bn\n",
            "I1026 00:43:52.140597 140005746440064 utils.py:45] yolo_conv_1/conv2d_60 bn\n",
            "I1026 00:43:52.144347 140005746440064 utils.py:45] yolo_conv_1/conv2d_61 bn\n",
            "I1026 00:43:52.155519 140005746440064 utils.py:45] yolo_conv_1/conv2d_62 bn\n",
            "I1026 00:43:52.158550 140005746440064 utils.py:45] yolo_conv_1/conv2d_63 bn\n",
            "I1026 00:43:52.170673 140005746440064 utils.py:45] yolo_conv_1/conv2d_64 bn\n",
            "I1026 00:43:52.174106 140005746440064 utils.py:45] yolo_output_1/conv2d_65 bn\n",
            "I1026 00:43:52.185758 140005746440064 utils.py:45] yolo_output_1/conv2d_66 bias\n",
            "I1026 00:43:52.188126 140005746440064 utils.py:45] yolo_conv_2/conv2d_67 bn\n",
            "I1026 00:43:52.190442 140005746440064 utils.py:45] yolo_conv_2/conv2d_68 bn\n",
            "I1026 00:43:52.192780 140005746440064 utils.py:45] yolo_conv_2/conv2d_69 bn\n",
            "I1026 00:43:52.197604 140005746440064 utils.py:45] yolo_conv_2/conv2d_70 bn\n",
            "I1026 00:43:52.200395 140005746440064 utils.py:45] yolo_conv_2/conv2d_71 bn\n",
            "I1026 00:43:52.206318 140005746440064 utils.py:45] yolo_conv_2/conv2d_72 bn\n",
            "I1026 00:43:52.208543 140005746440064 utils.py:45] yolo_output_2/conv2d_73 bn\n",
            "I1026 00:43:52.213317 140005746440064 utils.py:45] yolo_output_2/conv2d_74 bias\n",
            "I1026 00:43:52.214691 140005746440064 convert.py:27] weights loaded\n",
            "2020-10-26 00:43:52.232911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-26 00:43:57.357373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "I1026 00:43:59.302213 140005746440064 convert.py:31] sanity check passed\n",
            "I1026 00:44:00.677439 140005746440064 convert.py:34] weights saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj_qRv3N2vYp"
      },
      "source": [
        "Now that we have all of the files needed for YOLO, we are ready to use it to recognize components of an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PSGz0NN2vYq"
      },
      "source": [
        "import os\n",
        "os.remove(filename_convert_script)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2x1e_GX2vYt"
      },
      "source": [
        "# Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrgrYjKGJ-aW",
        "outputId": "c0e03dac-80ec-437b-a2f2-1a6bf5cc2b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "pip install requests\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjTVwPfq2vYu"
      },
      "source": [
        "import time\n",
        "from absl import app, flags, logging\n",
        "from absl.flags import FLAGS\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (YoloV3, YoloV3Tiny)\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "import sys\n",
        "from PIL import Image, ImageFile\n",
        "import requests\n",
        "\n",
        "# Flags are used to define several options for YOLO.\n",
        "flags.DEFINE_string('classes', filename_classes, 'path to classes file')\n",
        "flags.DEFINE_string('weights', filename_converted_weights, 'path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
        "FLAGS([sys.argv[0]])\n",
        "\n",
        "# Locate devices to run YOLO on (e.g. GPU)\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RIXzsbs2vYw",
        "outputId": "5223bb75-cdc7-437e-9810-ec4fdb4ef550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# This assignment does not use the \"Tiny version\"\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "\n",
        "# Load weights and classes\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "print('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "print('classes loaded')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights loaded\n",
            "classes loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE3zz5HH2vY0"
      },
      "source": [
        "Modify the code below to create your solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i0ss7vYXdlq"
      },
      "source": [
        "col_list = ['image','person','car','bicycle','motorbike','umbrella','handbag']\n",
        "df = pd.DataFrame(columns= col_list)\n",
        "for i in range(10):\n",
        "        df.loc[i] = [i+1,0,0,0,0,0,0]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXlJ3sW6XhKD",
        "outputId": "1fa8334b-dcb1-4ed8-8cec-8154e7062b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>person</th>\n",
              "      <th>car</th>\n",
              "      <th>bicycle</th>\n",
              "      <th>motorbike</th>\n",
              "      <th>umbrella</th>\n",
              "      <th>handbag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image person car bicycle motorbike umbrella handbag\n",
              "0     1      0   0       0         0        0       0\n",
              "1     2      0   0       0         0        0       0\n",
              "2     3      0   0       0         0        0       0\n",
              "3     4      0   0       0         0        0       0\n",
              "4     5      0   0       0         0        0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxjM7Uac2vY0",
        "outputId": "129dd576-bd07-41f5-9fe8-71a6dc213be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_img_stats():\n",
        "\n",
        "    # Modifications: Add desired columns and updated the data frame; submit_df\n",
        "    col_list = ['image','person','car','bicycle','motorbike','umbrella','handbag']\n",
        "    df = pd.DataFrame(columns= col_list)\n",
        "\n",
        "    # Create 10 rows for 10 links of images\n",
        "    for i in range(10):\n",
        "        df.loc[i] = [i+1,0,0,0,0,0,0]\n",
        "    # create dictionary with keys from submit_df columns (this is to hold the vals\n",
        "    # while iterating\n",
        "    dict_vals = dict.fromkeys(df.columns, 0)\n",
        "\n",
        "\n",
        "    for file_idx in range(10):\n",
        "        url = f\"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{file_idx+1}.png\"\n",
        "        response = requests.get(url)\n",
        "        img_raw = tf.image.decode_image(response.content, channels=3)\n",
        "        print(\"now iterating: .......\", url)\n",
        "        # Preprocess image\n",
        "        img = tf.expand_dims(img_raw, 0)\n",
        "        img = transform_images(img, FLAGS.size)\n",
        "\n",
        "        # Desired threshold (any sub-image below this confidence level will be ignored.)\n",
        "        FLAGS.yolo_score_threshold = 0.1\n",
        "\n",
        "        # Recognize and report results\n",
        "        boxes, scores, classes, nums = yolo(img)\n",
        "\n",
        "        #iterate the data to find out the count for each column\n",
        "        for i in range(nums[0]):\n",
        "            data_name = class_names[int(classes[0][i])]\n",
        "            if data_name in dict_vals:\n",
        "                dict_vals[data_name] += 1\n",
        "        #update the stats to final data frame\n",
        "        for key_val in dict_vals:\n",
        "            print(key_val,dict_vals[key_val])\n",
        "            df[key_val].loc[file_idx] = dict_vals[key_val]\n",
        "        df['image'].loc[file_idx] = file_idx+1\n",
        "        \n",
        "\n",
        "    #print('detections:')\n",
        "    #for i in range(nums[0]):\n",
        "     #   cls = class_names[int(classes[0][i])]\n",
        "      #  score = np.array(scores[0][i])\n",
        "       # box = np.array(boxes[0][i])\n",
        "       # print(f\"\\t{cls}, {score}, {box}\")\n",
        "    #item_iterator += 1\n",
        "\n",
        "    return (df)\n",
        "\n",
        "final_data = get_img_stats()\n",
        "\n",
        "\n",
        "\n",
        "print(final_data)\n",
        "\n",
        "# This is your student key that I emailed to you at the beginnning of the semester.\n",
        "key = \"JNAl4M33jgax0oM1GJFuF6QHnAk58HWT3FElTJwQ\"  # This is an example key and will not work.\n",
        "\n",
        "# You must also identify your source file.  (modify for your local setup)\n",
        "# file='/content/drive/My Drive/Colab Notebooks/assignment_yourname_class7.ipynb'  # Google CoLab\n",
        "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class7.ipynb'  # Windows\n",
        "file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class7.ipynb'  # Mac/Linux\n",
        "\n",
        "#submit(source_file=file,data=[submit_df],key=key,no=7)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png\n",
            "image 0\n",
            "person 23\n",
            "car 0\n",
            "bicycle 3\n",
            "motorbike 4\n",
            "umbrella 0\n",
            "handbag 0\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.png\n",
            "image 0\n",
            "person 50\n",
            "car 1\n",
            "bicycle 11\n",
            "motorbike 6\n",
            "umbrella 0\n",
            "handbag 0\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.png\n",
            "image 0\n",
            "person 79\n",
            "car 1\n",
            "bicycle 11\n",
            "motorbike 6\n",
            "umbrella 3\n",
            "handbag 0\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.png\n",
            "image 0\n",
            "person 130\n",
            "car 1\n",
            "bicycle 17\n",
            "motorbike 7\n",
            "umbrella 4\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.png\n",
            "image 0\n",
            "person 179\n",
            "car 1\n",
            "bicycle 26\n",
            "motorbike 7\n",
            "umbrella 4\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.png\n",
            "image 0\n",
            "person 240\n",
            "car 1\n",
            "bicycle 28\n",
            "motorbike 8\n",
            "umbrella 5\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.png\n",
            "image 0\n",
            "person 292\n",
            "car 1\n",
            "bicycle 28\n",
            "motorbike 8\n",
            "umbrella 5\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.png\n",
            "image 0\n",
            "person 348\n",
            "car 1\n",
            "bicycle 29\n",
            "motorbike 8\n",
            "umbrella 5\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.png\n",
            "image 0\n",
            "person 381\n",
            "car 2\n",
            "bicycle 29\n",
            "motorbike 8\n",
            "umbrella 6\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.png\n",
            "image 0\n",
            "person 420\n",
            "car 2\n",
            "bicycle 30\n",
            "motorbike 8\n",
            "umbrella 6\n",
            "handbag 1\n",
            "  image person car bicycle motorbike umbrella handbag\n",
            "0     1     23   0       3         4        0       0\n",
            "1     2     50   1      11         6        0       0\n",
            "2     3     79   1      11         6        3       0\n",
            "3     4    130   1      17         7        4       1\n",
            "4     5    179   1      26         7        4       1\n",
            "5     6    240   1      28         8        5       1\n",
            "6     7    292   1      28         8        5       1\n",
            "7     8    348   1      29         8        5       1\n",
            "8     9    381   2      29         8        6       1\n",
            "9    10    420   2      30         8        6       1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYEW3R5OCpP5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGKf3JMLDs1S"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAZRgi3gSNsr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPHYXC-qSo4c",
        "outputId": "377451c9-f722-45a2-f0ad-a673d90e4b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#create dictionary to update the values\n",
        "dict_vals = dict.fromkeys(submit_df.columns, 0)\n",
        "for key_val in dict_vals:\n",
        "    print(key_val, dict_vals[key_val])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image 0\n",
            "person 0\n",
            "car 0\n",
            "bicycle 0\n",
            "motorbike 0\n",
            "umbrella 0\n",
            "handbag 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7n2MoDo9kl9",
        "outputId": "8ace4d71-9ecb-4510-9ca9-a54ae19e4657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dict_vals"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bicycle': 3,\n",
              " 'car': 0,\n",
              " 'handbag': 0,\n",
              " 'image': 0,\n",
              " 'motorbike': 4,\n",
              " 'person': 23,\n",
              " 'umbrella': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3evbSuz9lxL",
        "outputId": "62c98e18-3e2d-404a-aba2-c588c501b402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "submit_df["
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVkhn2WrAuom",
        "outputId": "954868e7-d751-458e-f829-4b24a60b2116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function dict.values>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xFxoc_1BXPb",
        "outputId": "b5b50132-be70-4aaa-e50a-f51067099742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#img_iterator\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image 0\n",
            "person 23\n",
            "car 0\n",
            "bicycle 3\n",
            "motorbike 4\n",
            "umbrella 0\n",
            "handbag 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0DcGWrkCbnS",
        "outputId": "8752adad-0e1d-42cb-b81a-fdd4e943fe5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "submit_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>person</th>\n",
              "      <th>car</th>\n",
              "      <th>bicycle</th>\n",
              "      <th>motorbike</th>\n",
              "      <th>umbrella</th>\n",
              "      <th>handbag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image person car bicycle motorbike umbrella handbag\n",
              "0     0     23   0       3         4        0       0\n",
              "1     2      0   0       0         0        0       0\n",
              "2     3      0   0       0         0        0       0\n",
              "3     4      0   0       0         0        0       0\n",
              "4     5      0   0       0         0        0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4pt-7azC0_d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}