{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "Wk7-assignment-class7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codesamskaaraH/WU_assignments/blob/main/Wk7_assignment_class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgNjEIDh2vX9"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSJl8ZoSucQK"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
        "\n",
        "**Module 7 Assignment: Computer Vision Neural Network**\n",
        "\n",
        "**Student Name: Your Name**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okt7vSL52vYC"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7xrVUBv2vYE",
        "outputId": "b9aef199-abbd-4d5d-f3a8-0415a363e1dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return f\"{h}:{m:>02}:{s:>05.2f}\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eCUTf6n3BCb"
      },
      "source": [
        "# Assignment Submit Function\n",
        "\n",
        "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n",
        "\n",
        "**It is unlikely that should need to modify this function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHb2ceEO3Qil"
      },
      "source": [
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import io\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - List of pandas dataframes or images.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    payload = []\n",
        "    for item in data:\n",
        "        if type(item) is PIL.Image.Image:\n",
        "            buffered = BytesIO()\n",
        "            item.save(buffered, format=\"PNG\")\n",
        "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
        "        elif type(item) is pd.core.frame.DataFrame:\n",
        "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
        "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code==200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vNkxmQDucQN"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "For this assignment, you will use YOLO running on Google CoLab.  I suggest that you run this assignment on CoLab because the example code below is already setup to get you started with the correct versions of  YOLO on TensorFlow 2.0.\n",
        "\n",
        "For this assignment you are provided with 10 image files that contain 10 different webcam pictures taken at the [Venice Sidewalk Cafe](https://www.westland.net/beachcam/) a WebCam that has been in opration since 1996.  You can find the 10 images here:\n",
        "\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.png\n",
        "\n",
        "You can see a sample of the WebCam here:\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png)\n",
        "\n",
        "YOLO does quite well-recognizing objects in this webcam, as the following image illustrates.\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/predictions.jpg)\n",
        "\n",
        "You are to write a script that counts the number of certain objects in each of the images.  Specifically, you are looking for:\n",
        "\n",
        "* person\n",
        "* car\n",
        "* bicycle\n",
        "* motorbike\n",
        "* umbrella\n",
        "* handbag\n",
        "\n",
        "It is essential that your use YOLO with a threshold of 10% if you want your results to match mine. The sample code below already contains this setting.  Your program can set this threshold with the following command.\n",
        "\n",
        "* FLAGS.yolo_score_threshold = 0.1\n",
        "\n",
        "Your submitted data frame should also contain a column that identifies which image generated each row.  This column should be named **image** and contain integer numbers between 1 and 10.  There should be 10 rows in total.  The complete data frame should look something like this (not necessarily exactly these numbers).\n",
        "\n",
        "|image|person|car|bicycle|motorbike|umbrella|handbag|\n",
        "|-|-|-|-|-|-|-|\n",
        "|1|23|0|3|4|0|0|\n",
        "|2|27|1|8|2|0|0|\n",
        "|3|29|0|0|0|3|0|\n",
        "|...|...|...|...|...|...|...|\n",
        "\n",
        "\n",
        "The following code sets up YOLO and then dumps the classification information for the first image.  This notebook only serves to get you started.  Read in all ten images and generate a data frame that looks like the following. Use the **submit** function as you did in previous assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI9XFHWf2vYY"
      },
      "source": [
        "### Installing YoloV3-TF2\n",
        "\n",
        "The following code is taken from the module, it installs YoLoV3-TF2 if not already installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCM70ViM2vYZ",
        "outputId": "394f2045-d954-40a2-bfc8-19ee44b8dfbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install git+https://github.com/zzh8829/yolov3-tf2.git@master"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/zzh8829/yolov3-tf2.git@master\n",
            "  Cloning https://github.com/zzh8829/yolov3-tf2.git (to revision master) to /tmp/pip-req-build-i5jfys1v\n",
            "  Running command git clone -q https://github.com/zzh8829/yolov3-tf2.git /tmp/pip-req-build-i5jfys1v\n",
            "Requirement already satisfied (use --upgrade to upgrade): yolov3-tf2==0.1 from git+https://github.com/zzh8829/yolov3-tf2.git@master in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: yolov3-tf2\n",
            "  Building wheel for yolov3-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yolov3-tf2: filename=yolov3_tf2-0.1-cp36-none-any.whl size=8851 sha256=ea623bae4771cbfea72809b7fb8318ae2a0d499b0d47efdab73a6e9236a78a65\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-23gaeh00/wheels/59/1b/97/905ab51e9c0330efe8c3c518aff17de4ee91100412cd6dd553\n",
            "Successfully built yolov3-tf2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyWQeEDu2vYf"
      },
      "source": [
        "The following code is taken from the module, it downloads needed files for YoLoV3-TF2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2ZVTgPO2vYf",
        "outputId": "264c094d-c595-4504-deaa-878107c3622b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "if COLAB:\n",
        "  ROOT = '/content/drive/My Drive/projects/t81_558_dlearning/yolo'\n",
        "else:\n",
        "  ROOT = os.path.join(os.getcwd(),'data')\n",
        "\n",
        "filename_darknet_weights = tf.keras.utils.get_file(\n",
        "    os.path.join(ROOT,'yolov3.weights'),\n",
        "    origin='https://pjreddie.com/media/files/yolov3.weights')\n",
        "TINY = False\n",
        "\n",
        "filename_convert_script = tf.keras.utils.get_file(\n",
        "    os.path.join(os.getcwd(),'convert.py'),\n",
        "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py')\n",
        "\n",
        "filename_classes = tf.keras.utils.get_file(\n",
        "    os.path.join(ROOT,'coco.names'),\n",
        "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/data/coco.names')\n",
        "filename_converted_weights = os.path.join(ROOT,'yolov3.tf')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py\n",
            "\r8192/1277 [================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99-qKwt-2vYl"
      },
      "source": [
        "### Transfering Weights\n",
        "\n",
        "The following code is taken from the module, it transfers preloaded weights into YOLO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woAO2zJP2vYl",
        "outputId": "fa34ad78-37c7-47d0-e6df-e25dbddcdc25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys\n",
        "!{sys.executable} \"{filename_convert_script}\" --weights \"{filename_darknet_weights}\" --output \"{filename_converted_weights}\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-25 00:24:01.332634: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-25 00:24:02.738813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-25 00:24:02.743662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:24:02.744288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-10-25 00:24:02.744337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-25 00:24:02.746080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-25 00:24:02.747969: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-25 00:24:02.748313: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-25 00:24:02.750213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-25 00:24:02.751208: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-25 00:24:02.755065: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-25 00:24:02.755188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:24:02.755845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:24:02.756400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-25 00:24:02.780288: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-10-25 00:24:02.780477: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x192ca00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-25 00:24:02.780523: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-25 00:24:02.881980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:24:02.882709: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x192cf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-25 00:24:02.882743: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-25 00:24:02.882960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:24:02.883567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-10-25 00:24:02.883617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-25 00:24:02.883679: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-25 00:24:02.883703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-25 00:24:02.883730: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-25 00:24:02.883752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-25 00:24:02.883772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-25 00:24:02.883794: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-25 00:24:02.883875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:24:02.884481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:24:02.885044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-25 00:24:02.885093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-25 00:24:03.519092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-25 00:24:03.519152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-25 00:24:03.519166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-25 00:24:03.519368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:24:03.520116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:24:03.520964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13277 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Model: \"yolov3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "yolo_darknet (Functional)       ((None, None, None,  40620640    input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_0 (Functional)        (None, None, None, 5 11024384    yolo_darknet[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_1 (Functional)        (None, None, None, 2 2957312     yolo_conv_0[0][0]                \n",
            "                                                                 yolo_darknet[0][1]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_2 (Functional)        (None, None, None, 1 741376      yolo_conv_1[0][0]                \n",
            "                                                                 yolo_darknet[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_0 (Functional)      (None, None, None, 3 4984063     yolo_conv_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_1 (Functional)      (None, None, None, 3 1312511     yolo_conv_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_2 (Functional)      (None, None, None, 3 361471      yolo_conv_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_0 (Lambda)           ((None, None, None,  0           yolo_output_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_1 (Lambda)           ((None, None, None,  0           yolo_output_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_2 (Lambda)           ((None, None, None,  0           yolo_output_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_nms (Lambda)               ((None, 100, 4), (No 0           yolo_boxes_0[0][0]               \n",
            "                                                                 yolo_boxes_0[0][1]               \n",
            "                                                                 yolo_boxes_0[0][2]               \n",
            "                                                                 yolo_boxes_1[0][0]               \n",
            "                                                                 yolo_boxes_1[0][1]               \n",
            "                                                                 yolo_boxes_1[0][2]               \n",
            "                                                                 yolo_boxes_2[0][0]               \n",
            "                                                                 yolo_boxes_2[0][1]               \n",
            "                                                                 yolo_boxes_2[0][2]               \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "I1025 00:24:06.584219 140260381595520 convert.py:24] model created\n",
            "I1025 00:24:06.585879 140260381595520 utils.py:45] yolo_darknet/conv2d bn\n",
            "I1025 00:24:06.588057 140260381595520 utils.py:45] yolo_darknet/conv2d_1 bn\n",
            "I1025 00:24:06.590911 140260381595520 utils.py:45] yolo_darknet/conv2d_2 bn\n",
            "I1025 00:24:06.593116 140260381595520 utils.py:45] yolo_darknet/conv2d_3 bn\n",
            "I1025 00:24:06.595763 140260381595520 utils.py:45] yolo_darknet/conv2d_4 bn\n",
            "I1025 00:24:06.598745 140260381595520 utils.py:45] yolo_darknet/conv2d_5 bn\n",
            "I1025 00:24:06.601383 140260381595520 utils.py:45] yolo_darknet/conv2d_6 bn\n",
            "I1025 00:24:06.608938 140260381595520 utils.py:45] yolo_darknet/conv2d_7 bn\n",
            "I1025 00:24:06.611010 140260381595520 utils.py:45] yolo_darknet/conv2d_8 bn\n",
            "I1025 00:24:06.613569 140260381595520 utils.py:45] yolo_darknet/conv2d_9 bn\n",
            "I1025 00:24:06.618659 140260381595520 utils.py:45] yolo_darknet/conv2d_10 bn\n",
            "I1025 00:24:06.620981 140260381595520 utils.py:45] yolo_darknet/conv2d_11 bn\n",
            "I1025 00:24:06.625338 140260381595520 utils.py:45] yolo_darknet/conv2d_12 bn\n",
            "I1025 00:24:06.627653 140260381595520 utils.py:45] yolo_darknet/conv2d_13 bn\n",
            "I1025 00:24:06.632349 140260381595520 utils.py:45] yolo_darknet/conv2d_14 bn\n",
            "I1025 00:24:06.634750 140260381595520 utils.py:45] yolo_darknet/conv2d_15 bn\n",
            "I1025 00:24:06.639054 140260381595520 utils.py:45] yolo_darknet/conv2d_16 bn\n",
            "I1025 00:24:06.641374 140260381595520 utils.py:45] yolo_darknet/conv2d_17 bn\n",
            "I1025 00:24:06.645752 140260381595520 utils.py:45] yolo_darknet/conv2d_18 bn\n",
            "I1025 00:24:06.648108 140260381595520 utils.py:45] yolo_darknet/conv2d_19 bn\n",
            "I1025 00:24:06.652655 140260381595520 utils.py:45] yolo_darknet/conv2d_20 bn\n",
            "I1025 00:24:06.654966 140260381595520 utils.py:45] yolo_darknet/conv2d_21 bn\n",
            "I1025 00:24:06.659142 140260381595520 utils.py:45] yolo_darknet/conv2d_22 bn\n",
            "I1025 00:24:06.661611 140260381595520 utils.py:45] yolo_darknet/conv2d_23 bn\n",
            "I1025 00:24:06.665918 140260381595520 utils.py:45] yolo_darknet/conv2d_24 bn\n",
            "I1025 00:24:06.668220 140260381595520 utils.py:45] yolo_darknet/conv2d_25 bn\n",
            "I1025 00:24:06.672543 140260381595520 utils.py:45] yolo_darknet/conv2d_26 bn\n",
            "I1025 00:24:06.685534 140260381595520 utils.py:45] yolo_darknet/conv2d_27 bn\n",
            "I1025 00:24:06.688674 140260381595520 utils.py:45] yolo_darknet/conv2d_28 bn\n",
            "I1025 00:24:06.699240 140260381595520 utils.py:45] yolo_darknet/conv2d_29 bn\n",
            "I1025 00:24:06.702713 140260381595520 utils.py:45] yolo_darknet/conv2d_30 bn\n",
            "I1025 00:24:06.712958 140260381595520 utils.py:45] yolo_darknet/conv2d_31 bn\n",
            "I1025 00:24:06.716116 140260381595520 utils.py:45] yolo_darknet/conv2d_32 bn\n",
            "I1025 00:24:06.726608 140260381595520 utils.py:45] yolo_darknet/conv2d_33 bn\n",
            "I1025 00:24:06.729570 140260381595520 utils.py:45] yolo_darknet/conv2d_34 bn\n",
            "I1025 00:24:06.740579 140260381595520 utils.py:45] yolo_darknet/conv2d_35 bn\n",
            "I1025 00:24:06.743768 140260381595520 utils.py:45] yolo_darknet/conv2d_36 bn\n",
            "I1025 00:24:06.754343 140260381595520 utils.py:45] yolo_darknet/conv2d_37 bn\n",
            "I1025 00:24:06.757405 140260381595520 utils.py:45] yolo_darknet/conv2d_38 bn\n",
            "I1025 00:24:06.773432 140260381595520 utils.py:45] yolo_darknet/conv2d_39 bn\n",
            "I1025 00:24:06.776725 140260381595520 utils.py:45] yolo_darknet/conv2d_40 bn\n",
            "I1025 00:24:06.787324 140260381595520 utils.py:45] yolo_darknet/conv2d_41 bn\n",
            "I1025 00:24:06.790482 140260381595520 utils.py:45] yolo_darknet/conv2d_42 bn\n",
            "I1025 00:24:06.801188 140260381595520 utils.py:45] yolo_darknet/conv2d_43 bn\n",
            "I1025 00:24:06.855103 140260381595520 utils.py:45] yolo_darknet/conv2d_44 bn\n",
            "I1025 00:24:06.862836 140260381595520 utils.py:45] yolo_darknet/conv2d_45 bn\n",
            "I1025 00:24:06.906390 140260381595520 utils.py:45] yolo_darknet/conv2d_46 bn\n",
            "I1025 00:24:06.913657 140260381595520 utils.py:45] yolo_darknet/conv2d_47 bn\n",
            "I1025 00:24:06.958759 140260381595520 utils.py:45] yolo_darknet/conv2d_48 bn\n",
            "I1025 00:24:06.966242 140260381595520 utils.py:45] yolo_darknet/conv2d_49 bn\n",
            "I1025 00:24:07.010080 140260381595520 utils.py:45] yolo_darknet/conv2d_50 bn\n",
            "I1025 00:24:07.017376 140260381595520 utils.py:45] yolo_darknet/conv2d_51 bn\n",
            "I1025 00:24:07.067775 140260381595520 utils.py:45] yolo_conv_0/conv2d_52 bn\n",
            "I1025 00:24:07.075482 140260381595520 utils.py:45] yolo_conv_0/conv2d_53 bn\n",
            "I1025 00:24:07.123048 140260381595520 utils.py:45] yolo_conv_0/conv2d_54 bn\n",
            "I1025 00:24:07.130129 140260381595520 utils.py:45] yolo_conv_0/conv2d_55 bn\n",
            "I1025 00:24:07.175636 140260381595520 utils.py:45] yolo_conv_0/conv2d_56 bn\n",
            "I1025 00:24:07.182836 140260381595520 utils.py:45] yolo_output_0/conv2d_57 bn\n",
            "I1025 00:24:07.226555 140260381595520 utils.py:45] yolo_output_0/conv2d_58 bias\n",
            "I1025 00:24:07.230263 140260381595520 utils.py:45] yolo_conv_1/conv2d_59 bn\n",
            "I1025 00:24:07.233260 140260381595520 utils.py:45] yolo_conv_1/conv2d_60 bn\n",
            "I1025 00:24:07.237086 140260381595520 utils.py:45] yolo_conv_1/conv2d_61 bn\n",
            "I1025 00:24:07.247834 140260381595520 utils.py:45] yolo_conv_1/conv2d_62 bn\n",
            "I1025 00:24:07.250984 140260381595520 utils.py:45] yolo_conv_1/conv2d_63 bn\n",
            "I1025 00:24:07.262058 140260381595520 utils.py:45] yolo_conv_1/conv2d_64 bn\n",
            "I1025 00:24:07.265151 140260381595520 utils.py:45] yolo_output_1/conv2d_65 bn\n",
            "I1025 00:24:07.275223 140260381595520 utils.py:45] yolo_output_1/conv2d_66 bias\n",
            "I1025 00:24:07.277455 140260381595520 utils.py:45] yolo_conv_2/conv2d_67 bn\n",
            "I1025 00:24:07.280122 140260381595520 utils.py:45] yolo_conv_2/conv2d_68 bn\n",
            "I1025 00:24:07.282337 140260381595520 utils.py:45] yolo_conv_2/conv2d_69 bn\n",
            "I1025 00:24:07.286389 140260381595520 utils.py:45] yolo_conv_2/conv2d_70 bn\n",
            "I1025 00:24:07.288471 140260381595520 utils.py:45] yolo_conv_2/conv2d_71 bn\n",
            "I1025 00:24:07.292467 140260381595520 utils.py:45] yolo_conv_2/conv2d_72 bn\n",
            "I1025 00:24:07.294618 140260381595520 utils.py:45] yolo_output_2/conv2d_73 bn\n",
            "I1025 00:24:07.298709 140260381595520 utils.py:45] yolo_output_2/conv2d_74 bias\n",
            "I1025 00:24:07.300400 140260381595520 convert.py:27] weights loaded\n",
            "2020-10-25 00:24:07.307330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-25 00:24:09.074391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "I1025 00:24:09.889792 140260381595520 convert.py:31] sanity check passed\n",
            "I1025 00:24:11.086789 140260381595520 convert.py:34] weights saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj_qRv3N2vYp"
      },
      "source": [
        "Now that we have all of the files needed for YOLO, we are ready to use it to recognize components of an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PSGz0NN2vYq"
      },
      "source": [
        "import os\n",
        "os.remove(filename_convert_script)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2x1e_GX2vYt"
      },
      "source": [
        "# Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjTVwPfq2vYu",
        "outputId": "716d4dda-ad38-4d8d-a311-a1765b74fc60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "import time\n",
        "from absl import app, flags, logging\n",
        "from absl.flags import FLAGS\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (YoloV3, YoloV3Tiny)\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "import sys\n",
        "from PIL import Image, ImageFile\n",
        "import requests\n",
        "\n",
        "# Flags are used to define several options for YOLO.\n",
        "flags.DEFINE_string('classes', filename_classes, 'path to classes file')\n",
        "flags.DEFINE_string('weights', filename_converted_weights, 'path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
        "FLAGS([sys.argv[0]])\n",
        "\n",
        "# Locate devices to run YOLO on (e.g. GPU)\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DuplicateFlagError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-cca77b19e255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Flags are used to define several options for YOLO.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'classes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'path to classes file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_converted_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'path to weights file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tiny'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yolov3 or yolov3-tiny'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_string\u001b[0;34m(name, default, help, flag_values, **args)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDEFINE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[0;34m(parser, name, default, help, flag_values, serializer, module_name, **args)\u001b[0m\n\u001b[1;32m    101\u001b[0m   return DEFINE_flag(\n\u001b[1;32m    102\u001b[0m       \u001b[0m_flag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       module_name)\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'classes' is defined twice. First from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py, Second from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py.  Description from first occurrence: path to classes file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RIXzsbs2vYw",
        "outputId": "f71d6c3d-51c7-493d-d8cc-1fd5f64e5947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# This assignment does not use the \"Tiny version\"\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "\n",
        "# Load weights and classes\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "print('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "print('classes loaded')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights loaded\n",
            "classes loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE3zz5HH2vY0"
      },
      "source": [
        "Modify the code below to create your solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxjM7Uac2vY0",
        "outputId": "a7f35229-d4b6-47db-ad49-2588f22800e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_img_stats():\n",
        "\n",
        "    # Modifications: Add desired columns and updated the data frame; submit_df\n",
        "    col_list = ['image','person','car','bicycle','motorbike','umbrella','handbag']\n",
        "    df = pd.DataFrame(columns= col_list)\n",
        "\n",
        "    # Create 10 rows for 10 links of images\n",
        "    for i in range(10):\n",
        "        df.loc[i] = [i+1,0,0,0,0,0,0]\n",
        "    # create dictionary with keys from submit_df columns (this is to hold the vals\n",
        "    # while iterating\n",
        "    dict_vals = dict.fromkeys(df.columns, 0)\n",
        "\n",
        "\n",
        "    for file_idx in range(10):\n",
        "        url = f\"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{file_idx+1}.png\"\n",
        "        response = requests.get(url)\n",
        "        img_raw = tf.image.decode_image(response.content, channels=3)\n",
        "        print(\"now iterating: .......\", url)\n",
        "        # Preprocess image\n",
        "        img = tf.expand_dims(img_raw, 0)\n",
        "        img = transform_images(img, FLAGS.size)\n",
        "\n",
        "        # Desired threshold (any sub-image below this confidence level will be ignored.)\n",
        "        FLAGS.yolo_score_threshold = 0.1\n",
        "\n",
        "        # Recognize and report results\n",
        "        boxes, scores, classes, nums = yolo(img)\n",
        "\n",
        "        #iterate the data to find out the count for each column\n",
        "        for i in range(nums[0]):\n",
        "            data_name = class_names[int(classes[0][i])]\n",
        "            if data_name in dict_vals:\n",
        "                dict_vals[data_name] += 1\n",
        "        #update the stats to final data frame\n",
        "        for key_val in dict_vals:\n",
        "            print(key_val,dict_vals[key_val])\n",
        "            df[key_val].loc[file_idx] = dict_vals[key_val]\n",
        "\n",
        "\n",
        "    #print('detections:')\n",
        "    #for i in range(nums[0]):\n",
        "     #   cls = class_names[int(classes[0][i])]\n",
        "      #  score = np.array(scores[0][i])\n",
        "       # box = np.array(boxes[0][i])\n",
        "       # print(f\"\\t{cls}, {score}, {box}\")\n",
        "    #item_iterator += 1\n",
        "\n",
        "    return (df)\n",
        "\n",
        "final_data = get_img_stats()\n",
        "\n",
        "\n",
        "\n",
        "print(final_data)\n",
        "\n",
        "# This is your student key that I emailed to you at the beginnning of the semester.\n",
        "key = \"JNAl4M33jgax0oM1GJFuF6QHnAk58HWT3FElTJwQ\"  # This is an example key and will not work.\n",
        "\n",
        "# You must also identify your source file.  (modify for your local setup)\n",
        "# file='/content/drive/My Drive/Colab Notebooks/assignment_yourname_class7.ipynb'  # Google CoLab\n",
        "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class7.ipynb'  # Windows\n",
        "file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class7.ipynb'  # Mac/Linux\n",
        "\n",
        "#submit(source_file=file,data=[submit_df],key=key,no=7)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2ed02fed9fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mfinal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2ed02fed9fa5>\u001b[0m in \u001b[0;36mget_img_stats\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{file_idx+1}.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mimg_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"now iterating: .......\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYEW3R5OCpP5",
        "outputId": "58453653-ad24-4973-eab1-987747ce85fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dict_vals"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bicycle': 3,\n",
              " 'car': 0,\n",
              " 'handbag': 0,\n",
              " 'image': 0,\n",
              " 'motorbike': 4,\n",
              " 'person': 23,\n",
              " 'umbrella': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGKf3JMLDs1S"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "for i in range(10):\n",
        "     submit_df.loc[i] = [i+1,0,0,0,0,0,0]\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAZRgi3gSNsr",
        "outputId": "36eecbe1-09cb-4609-f943-bb98445e4912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "submit_df"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>person</th>\n",
              "      <th>car</th>\n",
              "      <th>bicycle</th>\n",
              "      <th>motorbike</th>\n",
              "      <th>umbrella</th>\n",
              "      <th>handbag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image person car bicycle motorbike umbrella handbag\n",
              "0     1      0   0       0         0        0       0\n",
              "1     2      0   0       0         0        0       0\n",
              "2     3      0   0       0         0        0       0\n",
              "3     4      0   0       0         0        0       0\n",
              "4     5      0   0       0         0        0       0\n",
              "5     6      0   0       0         0        0       0\n",
              "6     7      0   0       0         0        0       0\n",
              "7     8      0   0       0         0        0       0\n",
              "8     9      0   0       0         0        0       0\n",
              "9    10      0   0       0         0        0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPHYXC-qSo4c",
        "outputId": "377451c9-f722-45a2-f0ad-a673d90e4b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#create dictionary to update the values\n",
        "dict_vals = dict.fromkeys(submit_df.columns, 0)\n",
        "for key_val in dict_vals:\n",
        "    print(key_val, dict_vals[key_val])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image 0\n",
            "person 0\n",
            "car 0\n",
            "bicycle 0\n",
            "motorbike 0\n",
            "umbrella 0\n",
            "handbag 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7n2MoDo9kl9",
        "outputId": "8ace4d71-9ecb-4510-9ca9-a54ae19e4657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dict_vals"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bicycle': 3,\n",
              " 'car': 0,\n",
              " 'handbag': 0,\n",
              " 'image': 0,\n",
              " 'motorbike': 4,\n",
              " 'person': 23,\n",
              " 'umbrella': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3evbSuz9lxL",
        "outputId": "62c98e18-3e2d-404a-aba2-c588c501b402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "submit_df["
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVkhn2WrAuom",
        "outputId": "954868e7-d751-458e-f829-4b24a60b2116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function dict.values>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xFxoc_1BXPb",
        "outputId": "b5b50132-be70-4aaa-e50a-f51067099742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#img_iterator\n",
        "\n",
        "\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image 0\n",
            "person 23\n",
            "car 0\n",
            "bicycle 3\n",
            "motorbike 4\n",
            "umbrella 0\n",
            "handbag 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0DcGWrkCbnS",
        "outputId": "8752adad-0e1d-42cb-b81a-fdd4e943fe5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "submit_df.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>person</th>\n",
              "      <th>car</th>\n",
              "      <th>bicycle</th>\n",
              "      <th>motorbike</th>\n",
              "      <th>umbrella</th>\n",
              "      <th>handbag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image person car bicycle motorbike umbrella handbag\n",
              "0     0     23   0       3         4        0       0\n",
              "1     2      0   0       0         0        0       0\n",
              "2     3      0   0       0         0        0       0\n",
              "3     4      0   0       0         0        0       0\n",
              "4     5      0   0       0         0        0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4pt-7azC0_d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}