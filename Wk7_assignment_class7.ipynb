{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "Wk7-assignment-class7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codesamskaaraH/WU_assignments/blob/main/Wk7_assignment_class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgNjEIDh2vX9"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSJl8ZoSucQK"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
        "\n",
        "**Module 7 Assignment: Computer Vision Neural Network**\n",
        "\n",
        "**Student Name: Your Name**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okt7vSL52vYC"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7xrVUBv2vYE",
        "outputId": "4fe77d0b-a6bb-4583-8b2a-7e595f60643f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return f\"{h}:{m:>02}:{s:>05.2f}\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eCUTf6n3BCb"
      },
      "source": [
        "# Assignment Submit Function\n",
        "\n",
        "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n",
        "\n",
        "**It is unlikely that should need to modify this function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHb2ceEO3Qil"
      },
      "source": [
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import io\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - List of pandas dataframes or images.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    payload = []\n",
        "    for item in data:\n",
        "        if type(item) is PIL.Image.Image:\n",
        "            buffered = BytesIO()\n",
        "            item.save(buffered, format=\"PNG\")\n",
        "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
        "        elif type(item) is pd.core.frame.DataFrame:\n",
        "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
        "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code==200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vNkxmQDucQN"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "For this assignment, you will use YOLO running on Google CoLab.  I suggest that you run this assignment on CoLab because the example code below is already setup to get you started with the correct versions of  YOLO on TensorFlow 2.0.\n",
        "\n",
        "For this assignment you are provided with 10 image files that contain 10 different webcam pictures taken at the [Venice Sidewalk Cafe](https://www.westland.net/beachcam/) a WebCam that has been in opration since 1996.  You can find the 10 images here:\n",
        "\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.png\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.png\n",
        "\n",
        "You can see a sample of the WebCam here:\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png)\n",
        "\n",
        "YOLO does quite well-recognizing objects in this webcam, as the following image illustrates.\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/predictions.jpg)\n",
        "\n",
        "You are to write a script that counts the number of certain objects in each of the images.  Specifically, you are looking for:\n",
        "\n",
        "* person\n",
        "* car\n",
        "* bicycle\n",
        "* motorbike\n",
        "* umbrella\n",
        "* handbag\n",
        "\n",
        "It is essential that your use YOLO with a threshold of 10% if you want your results to match mine. The sample code below already contains this setting.  Your program can set this threshold with the following command.\n",
        "\n",
        "* FLAGS.yolo_score_threshold = 0.1\n",
        "\n",
        "Your submitted data frame should also contain a column that identifies which image generated each row.  This column should be named **image** and contain integer numbers between 1 and 10.  There should be 10 rows in total.  The complete data frame should look something like this (not necessarily exactly these numbers).\n",
        "\n",
        "|image|person|car|bicycle|motorbike|umbrella|handbag|\n",
        "|-|-|-|-|-|-|-|\n",
        "|1|23|0|3|4|0|0|\n",
        "|2|27|1|8|2|0|0|\n",
        "|3|29|0|0|0|3|0|\n",
        "|...|...|...|...|...|...|...|\n",
        "\n",
        "\n",
        "The following code sets up YOLO and then dumps the classification information for the first image.  This notebook only serves to get you started.  Read in all ten images and generate a data frame that looks like the following. Use the **submit** function as you did in previous assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI9XFHWf2vYY"
      },
      "source": [
        "### Installing YoloV3-TF2\n",
        "\n",
        "The following code is taken from the module, it installs YoLoV3-TF2 if not already installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCM70ViM2vYZ",
        "outputId": "bfe35a08-123a-4903-c531-e27ea0494697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install git+https://github.com/zzh8829/yolov3-tf2.git@master"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/zzh8829/yolov3-tf2.git@master\n",
            "  Cloning https://github.com/zzh8829/yolov3-tf2.git (to revision master) to /tmp/pip-req-build-b1e431zi\n",
            "  Running command git clone -q https://github.com/zzh8829/yolov3-tf2.git /tmp/pip-req-build-b1e431zi\n",
            "Building wheels for collected packages: yolov3-tf2\n",
            "  Building wheel for yolov3-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yolov3-tf2: filename=yolov3_tf2-0.1-cp36-none-any.whl size=8851 sha256=bde4428c7da3f9814256fbfec0444e04d3b7d5d98cff98b86f3a7a94380c1197\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_mj4q5am/wheels/59/1b/97/905ab51e9c0330efe8c3c518aff17de4ee91100412cd6dd553\n",
            "Successfully built yolov3-tf2\n",
            "Installing collected packages: yolov3-tf2\n",
            "Successfully installed yolov3-tf2-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyWQeEDu2vYf"
      },
      "source": [
        "The following code is taken from the module, it downloads needed files for YoLoV3-TF2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2ZVTgPO2vYf",
        "outputId": "696f8764-e7b9-49cc-8d0e-bcb034bfe380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "if COLAB:\n",
        "  ROOT = '/content/drive/My Drive/projects/t81_558_dlearning/yolo'\n",
        "else:\n",
        "  ROOT = os.path.join(os.getcwd(),'data')\n",
        "\n",
        "filename_darknet_weights = tf.keras.utils.get_file(\n",
        "    os.path.join(ROOT,'yolov3.weights'),\n",
        "    origin='https://pjreddie.com/media/files/yolov3.weights')\n",
        "TINY = False\n",
        "\n",
        "filename_convert_script = tf.keras.utils.get_file(\n",
        "    os.path.join(os.getcwd(),'convert.py'),\n",
        "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py')\n",
        "\n",
        "filename_classes = tf.keras.utils.get_file(\n",
        "    os.path.join(ROOT,'coco.names'),\n",
        "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/data/coco.names')\n",
        "filename_converted_weights = os.path.join(ROOT,'yolov3.tf')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py\n",
            "\r8192/1277 [================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99-qKwt-2vYl"
      },
      "source": [
        "### Transfering Weights\n",
        "\n",
        "The following code is taken from the module, it transfers preloaded weights into YOLO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woAO2zJP2vYl",
        "outputId": "c08380ba-8f24-4adc-c638-ca62b8b10380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys\n",
        "!{sys.executable} \"{filename_convert_script}\" --weights \"{filename_darknet_weights}\" --output \"{filename_converted_weights}\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-25 00:26:33.531992: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-25 00:26:35.541562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-25 00:26:35.596318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:26:35.597013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-10-25 00:26:35.597063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-25 00:26:35.776905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-25 00:26:35.934534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-25 00:26:35.947356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-25 00:26:36.230750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-25 00:26:36.243368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-25 00:26:36.763082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-25 00:26:36.763277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:26:36.764024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:26:36.764611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-25 00:26:36.841699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-10-25 00:26:36.841942: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1dfea00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-25 00:26:36.841974: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-25 00:26:36.979664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:26:36.980454: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1dfef40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-25 00:26:36.980499: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-25 00:26:36.981409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:26:36.982010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-10-25 00:26:36.982056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-25 00:26:36.982110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-25 00:26:36.982134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-25 00:26:36.982159: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-25 00:26:36.982181: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-25 00:26:36.982201: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-25 00:26:36.982222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-25 00:26:36.982309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:26:36.982952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:26:36.983523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-25 00:26:36.985385: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-25 00:26:40.760556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-25 00:26:40.760614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-25 00:26:40.760628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-25 00:26:40.763670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:26:40.764348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-25 00:26:40.764958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Model: \"yolov3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "yolo_darknet (Functional)       ((None, None, None,  40620640    input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_0 (Functional)        (None, None, None, 5 11024384    yolo_darknet[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_1 (Functional)        (None, None, None, 2 2957312     yolo_conv_0[0][0]                \n",
            "                                                                 yolo_darknet[0][1]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_2 (Functional)        (None, None, None, 1 741376      yolo_conv_1[0][0]                \n",
            "                                                                 yolo_darknet[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_0 (Functional)      (None, None, None, 3 4984063     yolo_conv_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_1 (Functional)      (None, None, None, 3 1312511     yolo_conv_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_2 (Functional)      (None, None, None, 3 361471      yolo_conv_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_0 (Lambda)           ((None, None, None,  0           yolo_output_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_1 (Lambda)           ((None, None, None,  0           yolo_output_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_2 (Lambda)           ((None, None, None,  0           yolo_output_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_nms (Lambda)               ((None, 100, 4), (No 0           yolo_boxes_0[0][0]               \n",
            "                                                                 yolo_boxes_0[0][1]               \n",
            "                                                                 yolo_boxes_0[0][2]               \n",
            "                                                                 yolo_boxes_1[0][0]               \n",
            "                                                                 yolo_boxes_1[0][1]               \n",
            "                                                                 yolo_boxes_1[0][2]               \n",
            "                                                                 yolo_boxes_2[0][0]               \n",
            "                                                                 yolo_boxes_2[0][1]               \n",
            "                                                                 yolo_boxes_2[0][2]               \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "I1025 00:26:43.956360 139707585378176 convert.py:24] model created\n",
            "I1025 00:26:44.159622 139707585378176 utils.py:45] yolo_darknet/conv2d bn\n",
            "I1025 00:26:44.169229 139707585378176 utils.py:45] yolo_darknet/conv2d_1 bn\n",
            "I1025 00:26:44.174890 139707585378176 utils.py:45] yolo_darknet/conv2d_2 bn\n",
            "I1025 00:26:44.178694 139707585378176 utils.py:45] yolo_darknet/conv2d_3 bn\n",
            "I1025 00:26:44.183838 139707585378176 utils.py:45] yolo_darknet/conv2d_4 bn\n",
            "I1025 00:26:44.187217 139707585378176 utils.py:45] yolo_darknet/conv2d_5 bn\n",
            "I1025 00:26:44.189228 139707585378176 utils.py:45] yolo_darknet/conv2d_6 bn\n",
            "I1025 00:26:44.191935 139707585378176 utils.py:45] yolo_darknet/conv2d_7 bn\n",
            "I1025 00:26:44.194051 139707585378176 utils.py:45] yolo_darknet/conv2d_8 bn\n",
            "I1025 00:26:44.196539 139707585378176 utils.py:45] yolo_darknet/conv2d_9 bn\n",
            "I1025 00:26:44.201501 139707585378176 utils.py:45] yolo_darknet/conv2d_10 bn\n",
            "I1025 00:26:44.203737 139707585378176 utils.py:45] yolo_darknet/conv2d_11 bn\n",
            "I1025 00:26:44.209752 139707585378176 utils.py:45] yolo_darknet/conv2d_12 bn\n",
            "I1025 00:26:44.227059 139707585378176 utils.py:45] yolo_darknet/conv2d_13 bn\n",
            "I1025 00:26:44.246345 139707585378176 utils.py:45] yolo_darknet/conv2d_14 bn\n",
            "I1025 00:26:44.251520 139707585378176 utils.py:45] yolo_darknet/conv2d_15 bn\n",
            "I1025 00:26:44.270144 139707585378176 utils.py:45] yolo_darknet/conv2d_16 bn\n",
            "I1025 00:26:44.281788 139707585378176 utils.py:45] yolo_darknet/conv2d_17 bn\n",
            "I1025 00:26:44.364746 139707585378176 utils.py:45] yolo_darknet/conv2d_18 bn\n",
            "I1025 00:26:44.373827 139707585378176 utils.py:45] yolo_darknet/conv2d_19 bn\n",
            "I1025 00:26:44.386070 139707585378176 utils.py:45] yolo_darknet/conv2d_20 bn\n",
            "I1025 00:26:44.389167 139707585378176 utils.py:45] yolo_darknet/conv2d_21 bn\n",
            "I1025 00:26:44.397504 139707585378176 utils.py:45] yolo_darknet/conv2d_22 bn\n",
            "I1025 00:26:44.402698 139707585378176 utils.py:45] yolo_darknet/conv2d_23 bn\n",
            "I1025 00:26:44.411470 139707585378176 utils.py:45] yolo_darknet/conv2d_24 bn\n",
            "I1025 00:26:44.416834 139707585378176 utils.py:45] yolo_darknet/conv2d_25 bn\n",
            "I1025 00:26:44.424971 139707585378176 utils.py:45] yolo_darknet/conv2d_26 bn\n",
            "I1025 00:26:44.439653 139707585378176 utils.py:45] yolo_darknet/conv2d_27 bn\n",
            "I1025 00:26:44.442719 139707585378176 utils.py:45] yolo_darknet/conv2d_28 bn\n",
            "I1025 00:26:44.458772 139707585378176 utils.py:45] yolo_darknet/conv2d_29 bn\n",
            "I1025 00:26:44.461778 139707585378176 utils.py:45] yolo_darknet/conv2d_30 bn\n",
            "I1025 00:26:44.471637 139707585378176 utils.py:45] yolo_darknet/conv2d_31 bn\n",
            "I1025 00:26:44.474634 139707585378176 utils.py:45] yolo_darknet/conv2d_32 bn\n",
            "I1025 00:26:44.500741 139707585378176 utils.py:45] yolo_darknet/conv2d_33 bn\n",
            "I1025 00:26:44.507082 139707585378176 utils.py:45] yolo_darknet/conv2d_34 bn\n",
            "I1025 00:26:44.524624 139707585378176 utils.py:45] yolo_darknet/conv2d_35 bn\n",
            "I1025 00:26:44.531495 139707585378176 utils.py:45] yolo_darknet/conv2d_36 bn\n",
            "I1025 00:26:44.691046 139707585378176 utils.py:45] yolo_darknet/conv2d_37 bn\n",
            "I1025 00:26:44.695584 139707585378176 utils.py:45] yolo_darknet/conv2d_38 bn\n",
            "I1025 00:26:44.713409 139707585378176 utils.py:45] yolo_darknet/conv2d_39 bn\n",
            "I1025 00:26:44.716602 139707585378176 utils.py:45] yolo_darknet/conv2d_40 bn\n",
            "I1025 00:26:44.726969 139707585378176 utils.py:45] yolo_darknet/conv2d_41 bn\n",
            "I1025 00:26:44.730061 139707585378176 utils.py:45] yolo_darknet/conv2d_42 bn\n",
            "I1025 00:26:44.747376 139707585378176 utils.py:45] yolo_darknet/conv2d_43 bn\n",
            "I1025 00:26:45.338971 139707585378176 utils.py:45] yolo_darknet/conv2d_44 bn\n",
            "I1025 00:26:45.347052 139707585378176 utils.py:45] yolo_darknet/conv2d_45 bn\n",
            "I1025 00:26:45.398120 139707585378176 utils.py:45] yolo_darknet/conv2d_46 bn\n",
            "I1025 00:26:45.406093 139707585378176 utils.py:45] yolo_darknet/conv2d_47 bn\n",
            "I1025 00:26:45.459243 139707585378176 utils.py:45] yolo_darknet/conv2d_48 bn\n",
            "I1025 00:26:45.467177 139707585378176 utils.py:45] yolo_darknet/conv2d_49 bn\n",
            "I1025 00:26:45.515508 139707585378176 utils.py:45] yolo_darknet/conv2d_50 bn\n",
            "I1025 00:26:45.523375 139707585378176 utils.py:45] yolo_darknet/conv2d_51 bn\n",
            "I1025 00:26:45.577946 139707585378176 utils.py:45] yolo_conv_0/conv2d_52 bn\n",
            "I1025 00:26:45.585946 139707585378176 utils.py:45] yolo_conv_0/conv2d_53 bn\n",
            "I1025 00:26:45.635867 139707585378176 utils.py:45] yolo_conv_0/conv2d_54 bn\n",
            "I1025 00:26:45.643940 139707585378176 utils.py:45] yolo_conv_0/conv2d_55 bn\n",
            "I1025 00:26:45.691093 139707585378176 utils.py:45] yolo_conv_0/conv2d_56 bn\n",
            "I1025 00:26:45.698710 139707585378176 utils.py:45] yolo_output_0/conv2d_57 bn\n",
            "I1025 00:26:45.745816 139707585378176 utils.py:45] yolo_output_0/conv2d_58 bias\n",
            "I1025 00:26:45.749539 139707585378176 utils.py:45] yolo_conv_1/conv2d_59 bn\n",
            "I1025 00:26:45.752452 139707585378176 utils.py:45] yolo_conv_1/conv2d_60 bn\n",
            "I1025 00:26:45.757890 139707585378176 utils.py:45] yolo_conv_1/conv2d_61 bn\n",
            "I1025 00:26:45.772076 139707585378176 utils.py:45] yolo_conv_1/conv2d_62 bn\n",
            "I1025 00:26:45.775140 139707585378176 utils.py:45] yolo_conv_1/conv2d_63 bn\n",
            "I1025 00:26:45.787842 139707585378176 utils.py:45] yolo_conv_1/conv2d_64 bn\n",
            "I1025 00:26:45.791086 139707585378176 utils.py:45] yolo_output_1/conv2d_65 bn\n",
            "I1025 00:26:45.801660 139707585378176 utils.py:45] yolo_output_1/conv2d_66 bias\n",
            "I1025 00:26:45.803872 139707585378176 utils.py:45] yolo_conv_2/conv2d_67 bn\n",
            "I1025 00:26:45.806383 139707585378176 utils.py:45] yolo_conv_2/conv2d_68 bn\n",
            "I1025 00:26:45.808664 139707585378176 utils.py:45] yolo_conv_2/conv2d_69 bn\n",
            "I1025 00:26:45.813023 139707585378176 utils.py:45] yolo_conv_2/conv2d_70 bn\n",
            "I1025 00:26:45.815186 139707585378176 utils.py:45] yolo_conv_2/conv2d_71 bn\n",
            "I1025 00:26:45.820375 139707585378176 utils.py:45] yolo_conv_2/conv2d_72 bn\n",
            "I1025 00:26:45.822634 139707585378176 utils.py:45] yolo_output_2/conv2d_73 bn\n",
            "I1025 00:26:45.826764 139707585378176 utils.py:45] yolo_output_2/conv2d_74 bias\n",
            "I1025 00:26:45.828470 139707585378176 convert.py:27] weights loaded\n",
            "2020-10-25 00:26:45.847803: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-25 00:26:50.976081: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "I1025 00:26:52.969319 139707585378176 convert.py:31] sanity check passed\n",
            "I1025 00:26:54.247652 139707585378176 convert.py:34] weights saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj_qRv3N2vYp"
      },
      "source": [
        "Now that we have all of the files needed for YOLO, we are ready to use it to recognize components of an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PSGz0NN2vYq"
      },
      "source": [
        "import os\n",
        "os.remove(filename_convert_script)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2x1e_GX2vYt"
      },
      "source": [
        "# Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrgrYjKGJ-aW",
        "outputId": "1ca8fade-119e-45da-e371-f7e0bb81fc72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "pip install requests\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjTVwPfq2vYu"
      },
      "source": [
        "import time\n",
        "from absl import app, flags, logging\n",
        "from absl.flags import FLAGS\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (YoloV3, YoloV3Tiny)\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "import sys\n",
        "from PIL import Image, ImageFile\n",
        "import requests\n",
        "\n",
        "# Flags are used to define several options for YOLO.\n",
        "flags.DEFINE_string('classes', filename_classes, 'path to classes file')\n",
        "flags.DEFINE_string('weights', filename_converted_weights, 'path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
        "FLAGS([sys.argv[0]])\n",
        "\n",
        "# Locate devices to run YOLO on (e.g. GPU)\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RIXzsbs2vYw",
        "outputId": "e141287d-34f8-45a4-8ef7-42a29defa09a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# This assignment does not use the \"Tiny version\"\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "\n",
        "# Load weights and classes\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "print('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "print('classes loaded')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights loaded\n",
            "classes loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE3zz5HH2vY0"
      },
      "source": [
        "Modify the code below to create your solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxjM7Uac2vY0",
        "outputId": "15016f43-b3bb-478d-bd21-cfb18e10cf5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_img_stats():\n",
        "\n",
        "    # Modifications: Add desired columns and updated the data frame; submit_df\n",
        "    col_list = ['image','person','car','bicycle','motorbike','umbrella','handbag']\n",
        "    df = pd.DataFrame(columns= col_list)\n",
        "\n",
        "    # Create 10 rows for 10 links of images\n",
        "    for i in range(10):\n",
        "        df.loc[i] = [i+1,0,0,0,0,0,0]\n",
        "    # create dictionary with keys from submit_df columns (this is to hold the vals\n",
        "    # while iterating\n",
        "    dict_vals = dict.fromkeys(df.columns, 0)\n",
        "\n",
        "\n",
        "    for file_idx in range(10):\n",
        "        url = f\"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{file_idx+1}.png\"\n",
        "        response = requests.get(url)\n",
        "        img_raw = tf.image.decode_image(response.content, channels=3)\n",
        "        print(\"now iterating: .......\", url)\n",
        "        # Preprocess image\n",
        "        img = tf.expand_dims(img_raw, 0)\n",
        "        img = transform_images(img, FLAGS.size)\n",
        "\n",
        "        # Desired threshold (any sub-image below this confidence level will be ignored.)\n",
        "        FLAGS.yolo_score_threshold = 0.1\n",
        "\n",
        "        # Recognize and report results\n",
        "        boxes, scores, classes, nums = yolo(img)\n",
        "\n",
        "        #iterate the data to find out the count for each column\n",
        "        for i in range(nums[0]):\n",
        "            data_name = class_names[int(classes[0][i])]\n",
        "            if data_name in dict_vals:\n",
        "                dict_vals[data_name] += 1\n",
        "        #update the stats to final data frame\n",
        "        for key_val in dict_vals:\n",
        "            print(key_val,dict_vals[key_val])\n",
        "            df[key_val].loc[file_idx] = dict_vals[key_val]\n",
        "\n",
        "\n",
        "    #print('detections:')\n",
        "    #for i in range(nums[0]):\n",
        "     #   cls = class_names[int(classes[0][i])]\n",
        "      #  score = np.array(scores[0][i])\n",
        "       # box = np.array(boxes[0][i])\n",
        "       # print(f\"\\t{cls}, {score}, {box}\")\n",
        "    #item_iterator += 1\n",
        "\n",
        "    return (df)\n",
        "\n",
        "final_data = get_img_stats()\n",
        "\n",
        "\n",
        "\n",
        "print(final_data)\n",
        "\n",
        "# This is your student key that I emailed to you at the beginnning of the semester.\n",
        "key = \"JNAl4M33jgax0oM1GJFuF6QHnAk58HWT3FElTJwQ\"  # This is an example key and will not work.\n",
        "\n",
        "# You must also identify your source file.  (modify for your local setup)\n",
        "# file='/content/drive/My Drive/Colab Notebooks/assignment_yourname_class7.ipynb'  # Google CoLab\n",
        "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class7.ipynb'  # Windows\n",
        "file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class7.ipynb'  # Mac/Linux\n",
        "\n",
        "#submit(source_file=file,data=[submit_df],key=key,no=7)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png\n",
            "image 0\n",
            "person 23\n",
            "car 0\n",
            "bicycle 3\n",
            "motorbike 4\n",
            "umbrella 0\n",
            "handbag 0\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.png\n",
            "image 0\n",
            "person 50\n",
            "car 1\n",
            "bicycle 11\n",
            "motorbike 6\n",
            "umbrella 0\n",
            "handbag 0\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.png\n",
            "image 0\n",
            "person 79\n",
            "car 1\n",
            "bicycle 11\n",
            "motorbike 6\n",
            "umbrella 3\n",
            "handbag 0\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.png\n",
            "image 0\n",
            "person 130\n",
            "car 1\n",
            "bicycle 17\n",
            "motorbike 7\n",
            "umbrella 4\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.png\n",
            "image 0\n",
            "person 179\n",
            "car 1\n",
            "bicycle 26\n",
            "motorbike 7\n",
            "umbrella 4\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.png\n",
            "image 0\n",
            "person 240\n",
            "car 1\n",
            "bicycle 28\n",
            "motorbike 8\n",
            "umbrella 5\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.png\n",
            "image 0\n",
            "person 292\n",
            "car 1\n",
            "bicycle 28\n",
            "motorbike 8\n",
            "umbrella 5\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.png\n",
            "image 0\n",
            "person 348\n",
            "car 1\n",
            "bicycle 29\n",
            "motorbike 8\n",
            "umbrella 5\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.png\n",
            "image 0\n",
            "person 381\n",
            "car 2\n",
            "bicycle 29\n",
            "motorbike 8\n",
            "umbrella 6\n",
            "handbag 1\n",
            "now iterating: ....... https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.png\n",
            "image 0\n",
            "person 420\n",
            "car 2\n",
            "bicycle 30\n",
            "motorbike 8\n",
            "umbrella 6\n",
            "handbag 1\n",
            "  image person car bicycle motorbike umbrella handbag\n",
            "0     0     23   0       3         4        0       0\n",
            "1     0     50   1      11         6        0       0\n",
            "2     0     79   1      11         6        3       0\n",
            "3     0    130   1      17         7        4       1\n",
            "4     0    179   1      26         7        4       1\n",
            "5     0    240   1      28         8        5       1\n",
            "6     0    292   1      28         8        5       1\n",
            "7     0    348   1      29         8        5       1\n",
            "8     0    381   2      29         8        6       1\n",
            "9     0    420   2      30         8        6       1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYEW3R5OCpP5"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGKf3JMLDs1S"
      },
      "source": [
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAZRgi3gSNsr"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPHYXC-qSo4c",
        "outputId": "377451c9-f722-45a2-f0ad-a673d90e4b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#create dictionary to update the values\n",
        "dict_vals = dict.fromkeys(submit_df.columns, 0)\n",
        "for key_val in dict_vals:\n",
        "    print(key_val, dict_vals[key_val])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image 0\n",
            "person 0\n",
            "car 0\n",
            "bicycle 0\n",
            "motorbike 0\n",
            "umbrella 0\n",
            "handbag 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7n2MoDo9kl9",
        "outputId": "8ace4d71-9ecb-4510-9ca9-a54ae19e4657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dict_vals"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bicycle': 3,\n",
              " 'car': 0,\n",
              " 'handbag': 0,\n",
              " 'image': 0,\n",
              " 'motorbike': 4,\n",
              " 'person': 23,\n",
              " 'umbrella': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3evbSuz9lxL",
        "outputId": "62c98e18-3e2d-404a-aba2-c588c501b402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "submit_df["
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVkhn2WrAuom",
        "outputId": "954868e7-d751-458e-f829-4b24a60b2116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function dict.values>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xFxoc_1BXPb",
        "outputId": "b5b50132-be70-4aaa-e50a-f51067099742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#img_iterator\n",
        "\n",
        "\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image 0\n",
            "person 23\n",
            "car 0\n",
            "bicycle 3\n",
            "motorbike 4\n",
            "umbrella 0\n",
            "handbag 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0DcGWrkCbnS",
        "outputId": "8752adad-0e1d-42cb-b81a-fdd4e943fe5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "submit_df.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>person</th>\n",
              "      <th>car</th>\n",
              "      <th>bicycle</th>\n",
              "      <th>motorbike</th>\n",
              "      <th>umbrella</th>\n",
              "      <th>handbag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image person car bicycle motorbike umbrella handbag\n",
              "0     0     23   0       3         4        0       0\n",
              "1     2      0   0       0         0        0       0\n",
              "2     3      0   0       0         0        0       0\n",
              "3     4      0   0       0         0        0       0\n",
              "4     5      0   0       0         0        0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4pt-7azC0_d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}